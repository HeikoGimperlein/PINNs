{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PINNs for 1D Burgers Equation (TF2.0).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "A1Mj-RBCn8MZ",
        "Al80f-lPoJjh",
        "ksKujMvUFRNW",
        "yOT-E8C4oAJN",
        "C9Ko6L87J2v_",
        "GkimJNtepkKi",
        "8FzMd65dpoHo",
        "T-Dt42ItxAqr",
        "IoN7tCmSGDeO",
        "dOPzdkKsJzA4",
        "OTxvp1nJGDeb",
        "fGrMDRc3w1ex",
        "rRGW4IW0w1e0",
        "JFS_u67iw1e2"
      ]
    },
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:light",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02UEmVFgDTFb"
      },
      "source": [
        "2020-11-05: \n",
        "- source: https://github.com/pierremtb/PINNs-TF2.0\n",
        "  - Original code from https://github.com/maziarraissi/PINNs\n",
        "  - Burgers' Equation code converted to TensorFlow 2.0\n",
        "  - (note: the three other examples are still TF1.0, or (for Schrödinger) problem of convergence in the original code)\n",
        "- modifications by Nicolas: \n",
        "  - added \"!sudo apt-get -qq install dvipng texlive-latex-extra texlive-fonts-recommended cm-super\" in \"Setting up modules/Tex packages\"\n",
        "  - added \"!pip install --upgrade pyDOE\" in \"Setting up modules/pip modules\"\n",
        "  - All four examples below are working\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Mj-RBCn8MZ"
      },
      "source": [
        "# 0. Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al80f-lPoJjh"
      },
      "source": [
        "## Getting the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3iHOMsdnNiq",
        "outputId": "27e8f6ae-8cc5-4af3-c3aa-59d1b822be4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/maziarraissi/PINNs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PINNs'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 741 (delta 1), reused 2 (delta 1), pack-reused 736\u001b[K\n",
            "Receiving objects: 100% (741/741), 474.48 MiB | 25.53 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "Checking out files: 100% (561/561), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtoc_dXgoOZq"
      },
      "source": [
        "## Setting up modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNMtDjXkFHaN"
      },
      "source": [
        "TeX packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaZCKcDsEVRP",
        "outputId": "59c98bb8-48bd-4229-a9a5-ce01c2581295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sudo apt-get -qq install texlive-fonts-recommended texlive-fonts-extra dvipng\n",
        "!sudo apt-get -qq install dvipng texlive-latex-extra texlive-fonts-recommended cm-super\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "(Reading database ... 230809 files and directories currently installed.)\n",
            "Preparing to unpack .../cm-super-minimal_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-11) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../cm-super_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super (0.3.4-11) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up cm-super-minimal (0.3.4-11) ...\n",
            "Setting up cm-super (0.3.4-11) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otc4Ap7qFMlf"
      },
      "source": [
        "Pip modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srpq4aQNoQ1E",
        "outputId": "222cb279-cb6c-47ea-ea57-50d7e6b8b837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pip uninstall -y tensorflow\n",
        "#!pip install tensorflow\n",
        "!pip install --upgrade pyDOE"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyDOE\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/ac/91fe4c039e2744466621343d3b8af4a485193ed0aab53af5b1db03be0989/pyDOE-0.3.8.zip\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.4.1)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-cp36-none-any.whl size=18178 sha256=d898565d805fa5f13f65f31c6aff120ced0db63a9c7a123c01022c8941825a95\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/c8/58/a6493bd415e8ba5735082b5e0c096d7c1f2933077a8ce34544\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKujMvUFRNW"
      },
      "source": [
        "## Imports, config, and utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEDn2fqlqctT",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# Manually making sure the numpy random seeds are \"the same\" on all devices\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODGREPvZpqUz"
      },
      "source": [
        "burgersutil.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgPvqJiYFnYG",
        "lines_to_next_cell": 0
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pyDOE import lhs\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "# \".\" for Colab/VSCode, and \"..\" for GitHub\n",
        "repoPath = os.path.join(\".\", \"PINNs\")\n",
        "# repoPath = os.path.join(\"..\", \"PINNs\")\n",
        "utilsPath = os.path.join(repoPath, \"Utilities\")\n",
        "dataPath = os.path.join(repoPath, \"main\", \"Data\")\n",
        "appDataPath = os.path.join(repoPath, \"appendix\", \"Data\")\n",
        "\n",
        "sys.path.insert(0, utilsPath)\n",
        "from plotting import newfig, savefig\n",
        "\n",
        "def prep_data(path, N_u=None, N_f=None, N_n=None, q=None, ub=None, lb=None, noise=0.0, idx_t_0=None, idx_t_1=None, N_0=None, N_1=None):\n",
        "    # Reading external data [t is 100x1, usol is 256x100 (solution), x is 256x1]\n",
        "    data = scipy.io.loadmat(path)\n",
        "\n",
        "    # Flatten makes [[]] into [], [:,None] makes it a column vector\n",
        "    t = data['t'].flatten()[:,None] # T x 1\n",
        "    x = data['x'].flatten()[:,None] # N x 1\n",
        "\n",
        "    # Keeping the 2D data for the solution data (real() is maybe to make it float by default, in case of zeroes)\n",
        "    Exact_u = np.real(data['usol']).T # T x N\n",
        "\n",
        "    if N_n != None and q != None and ub != None and lb != None and idx_t_0 != None and idx_t_1 != None:\n",
        "      dt = t[idx_t_1] - t[idx_t_0]\n",
        "      idx_x = np.random.choice(Exact_u.shape[1], N_n, replace=False) \n",
        "      x_0 = x[idx_x,:]\n",
        "      u_0 = Exact_u[idx_t_0:idx_t_0+1,idx_x].T\n",
        "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
        "        \n",
        "      # Boudanry data\n",
        "      x_1 = np.vstack((lb, ub))\n",
        "      \n",
        "      # Test data\n",
        "      x_star = x\n",
        "      u_star = Exact_u[idx_t_1,:]\n",
        "\n",
        "      # Load IRK weights\n",
        "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
        "      IRK_weights = np.reshape(tmp[0:q**2+q], (q+1,q))\n",
        "      IRK_times = tmp[q**2+q:]\n",
        "\n",
        "      return x, t, dt, Exact_u, x_0, u_0, x_1, x_star, u_star, IRK_weights, IRK_times\n",
        "\n",
        "    # Meshing x and t in 2D (256,100)\n",
        "    X, T = np.meshgrid(x,t)\n",
        "\n",
        "    # Preparing the inputs x and t (meshed as X, T) for predictions in one single array, as X_star\n",
        "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "\n",
        "    # Preparing the testing u_star\n",
        "    u_star = Exact_u.flatten()[:,None]\n",
        "                \n",
        "    # Noiseless data TODO: add support for noisy data    \n",
        "    idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
        "    X_u_train = X_star[idx,:]\n",
        "    u_train = u_star[idx,:]\n",
        "\n",
        "    if N_0 != None and N_1 != None:\n",
        "      Exact_u = Exact_u.T\n",
        "      idx_x = np.random.choice(Exact_u.shape[0], N_0, replace=False)\n",
        "      x_0 = x[idx_x,:]\n",
        "      u_0 = Exact_u[idx_x,idx_t_0][:,None]\n",
        "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
        "          \n",
        "      idx_x = np.random.choice(Exact_u.shape[0], N_1, replace=False)\n",
        "      x_1 = x[idx_x,:]\n",
        "      u_1 = Exact_u[idx_x,idx_t_1][:,None]\n",
        "      u_1 = u_1 + noise*np.std(u_1)*np.random.randn(u_1.shape[0], u_1.shape[1])\n",
        "      \n",
        "      dt = np.asscalar(t[idx_t_1] - t[idx_t_0])        \n",
        "      q = int(np.ceil(0.5*np.log(np.finfo(float).eps)/np.log(dt)))\n",
        "\n",
        "      # Load IRK weights\n",
        "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
        "      weights =  np.reshape(tmp[0:q**2+q], (q+1,q))     \n",
        "      IRK_alpha = weights[0:-1,:]\n",
        "      IRK_beta = weights[-1:,:] \n",
        "      return x_0, u_0, x_1, u_1, x, t, dt, q, Exact_u, IRK_alpha, IRK_beta\n",
        "\n",
        "    if N_f == None:\n",
        "      lb = X_star.min(axis=0)\n",
        "      ub = X_star.max(axis=0) \n",
        "      return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, ub, lb\n",
        "\n",
        "    # Domain bounds (lowerbounds upperbounds) [x, t], which are here ([-1.0, 0.0] and [1.0, 1.0])\n",
        "    lb = X_star.min(axis=0)\n",
        "    ub = X_star.max(axis=0) \n",
        "    # Getting the initial conditions (t=0)\n",
        "    xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
        "    uu1 = Exact_u[0:1,:].T\n",
        "    # Getting the lowest boundary conditions (x=-1) \n",
        "    xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
        "    uu2 = Exact_u[:,0:1]\n",
        "    # Getting the highest boundary conditions (x=1) \n",
        "    xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
        "    uu3 = Exact_u[:,-1:]\n",
        "    # Stacking them in multidimensional tensors for training (X_u_train is for now the continuous boundaries)\n",
        "    X_u_train = np.vstack([xx1, xx2, xx3])\n",
        "    u_train = np.vstack([uu1, uu2, uu3])\n",
        "\n",
        "    # Generating the x and t collocation points for f, with each having a N_f size\n",
        "    # We pointwise add and multiply to spread the LHS over the 2D domain\n",
        "    X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
        "\n",
        "    # Generating a uniform random sample from ints between 0, and the size of x_u_train, of size N_u (initial data size) and without replacement (unique)\n",
        "    idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
        "    # Getting the corresponding X_u_train (which is now scarce boundary/initial coordinates)\n",
        "    X_u_train = X_u_train[idx,:]\n",
        "    # Getting the corresponding u_train\n",
        "    u_train = u_train [idx,:]\n",
        "\n",
        "    return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, X_f_train, ub, lb\n",
        "\n",
        "class Logger(object):\n",
        "  def __init__(self, frequency=10):\n",
        "    print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "    print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "    print(\"GPU-accerelated: {}\".format(tf.test.is_gpu_available()))\n",
        "\n",
        "    self.start_time = time.time()\n",
        "    self.frequency = frequency\n",
        "\n",
        "  def __get_elapsed(self):\n",
        "    return datetime.fromtimestamp(time.time() - self.start_time).strftime(\"%M:%S\")\n",
        "\n",
        "  def __get_error_u(self):\n",
        "    return self.error_fn()\n",
        "\n",
        "  def set_error_fn(self, error_fn):\n",
        "    self.error_fn = error_fn\n",
        "  \n",
        "  def log_train_start(self, model):\n",
        "    print(\"\\nTraining started\")\n",
        "    print(\"================\")\n",
        "    self.model = model\n",
        "    print(self.model.summary())\n",
        "\n",
        "  def log_train_epoch(self, epoch, loss, custom=\"\", is_iter=False):\n",
        "    if epoch % self.frequency == 0:\n",
        "      print(f\"{'nt_epoch' if is_iter else 'tf_epoch'} = {epoch:6d}  elapsed = {self.__get_elapsed()}  loss = {loss:.4e}  error = {self.__get_error_u():.4e}  \" + custom)\n",
        "\n",
        "  def log_train_opt(self, name):\n",
        "    # print(f\"tf_epoch =      0  elapsed = 00:00  loss = 2.7391e-01  error = 9.0843e-01\")\n",
        "    print(f\"—— Starting {name} optimization ——\")\n",
        "\n",
        "  def log_train_end(self, epoch, custom=\"\"):\n",
        "    print(\"==================\")\n",
        "    print(f\"Training finished (epoch {epoch}): duration = {self.__get_elapsed()}  error = {self.__get_error_u():.4e}  \" + custom)\n",
        "\n",
        "def plot_inf_cont_results(X_star, u_pred, X_u_train, u_train, Exact_u, X, T, x, t, file=None):\n",
        "\n",
        "  # Interpolating the results on the whole (x,t) domain.\n",
        "  # griddata(points, values, points at which to interpolate, method)\n",
        "  U_pred = griddata(X_star, u_pred, (X, T), method='cubic')\n",
        "\n",
        "  # Creating the figures\n",
        "  fig, ax = newfig(1.0, 1.1)\n",
        "  ax.axis('off')\n",
        "\n",
        "  ####### Row 0: u(t,x) ##################    \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "\n",
        "  h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "\n",
        "  ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
        "\n",
        "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "  ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
        "\n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  ax.legend(frameon=False, loc = 'best')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "\n",
        "  ####### Row 1: u(t,x) slices ##################    \n",
        "  gs1 = gridspec.GridSpec(1, 3)\n",
        "  gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])\n",
        "  ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 2])\n",
        "  ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])    \n",
        "  ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  if file != None:\n",
        "    savefig(file)\n",
        "\n",
        "def plot_inf_disc_results(x_star, idx_t_0, idx_t_1, x_0, u_0, ub, lb, u_1_pred, Exact_u, x, t, file=None):\n",
        "  fig, ax = newfig(1.0, 1.2)\n",
        "  ax.axis('off')\n",
        "  \n",
        "  ####### Row 0: h(t,x) ##################    \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/2 + 0.1, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "  \n",
        "  h = ax.imshow(Exact_u.T, interpolation='nearest', cmap='rainbow', \n",
        "                extent=[t.min(), t.max(), x_star.min(), x_star.max()], \n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "      \n",
        "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "  ax.plot(t[idx_t_0]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[idx_t_1]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  \n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  leg = ax.legend(frameon=False, loc = 'best')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "  \n",
        "  \n",
        "  ####### Row 1: h(t,x) slices ##################    \n",
        "  gs1 = gridspec.GridSpec(1, 2)\n",
        "  gs1.update(top=1-1/2-0.05, bottom=0.15, left=0.15, right=0.85, wspace=0.5)\n",
        "  \n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x,Exact_u[idx_t_0,:], 'b-', linewidth = 2) \n",
        "  ax.plot(x_0, u_0, 'rx', linewidth = 2, label = 'Data')      \n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = %.2f$' % (t[idx_t_0]), fontsize = 10)\n",
        "  ax.set_xlim([lb-0.1, ub+0.1])\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.8, -0.3), ncol=2, frameon=False)\n",
        "\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x, Exact_u[idx_t_1,:], 'b-', linewidth = 2, label = 'Exact') \n",
        "  ax.plot(x_star, u_1_pred, 'r--', linewidth = 2, label = 'Prediction')      \n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = %.2f$' % (t[idx_t_1]), fontsize = 10)    \n",
        "  ax.set_xlim([lb-0.1, ub+0.1])\n",
        "  \n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.1, -0.3), ncol=2, frameon=False)\n",
        "    \n",
        "  plt.show()\n",
        "\n",
        "  if file != None:\n",
        "    savefig(file)\n",
        "\n",
        "\n",
        "def plot_ide_disc_results(x_star, t_star, idx_t_0, idx_t_1, x_0, u_0, x_1, u_1,\n",
        "  ub, lb, u_1_pred, Exact, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy,\n",
        "  x, t, file=None):  \n",
        "  fig, ax = newfig(1.0, 1.5)\n",
        "  ax.axis('off')\n",
        "  \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/3+0.05, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "      \n",
        "  h = ax.imshow(Exact, interpolation='nearest', cmap='rainbow',\n",
        "                extent=[t_star.min(),t_star.max(), lb[0], ub[0]],\n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "  \n",
        "  line = np.linspace(x_star.min(), x_star.max(), 2)[:,None]\n",
        "  ax.plot(t_star[idx_t_0]*np.ones((2,1)), line, 'w-', linewidth = 1.0)\n",
        "  ax.plot(t_star[idx_t_1]*np.ones((2,1)), line, 'w-', linewidth = 1.0)    \n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "  \n",
        "  gs1 = gridspec.GridSpec(1, 2)\n",
        "  gs1.update(top=1-1/3-0.1, bottom=1-2/3, left=0.15, right=0.85, wspace=0.5)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x_star,Exact[:,idx_t_0][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "  ax.plot(x_0, u_0, 'rx', linewidth = 2, label = 'Data')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t_0], u_0.shape[0]), fontsize = 10)\n",
        "  \n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x_star,Exact[:,idx_t_1][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "  ax.plot(x_1, u_1, 'rx', linewidth = 2, label = 'Data')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t_1], u_1.shape[0]), fontsize = 10)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(-0.3, -0.3), ncol=2, frameon=False)\n",
        "  \n",
        "  gs2 = gridspec.GridSpec(1, 2)\n",
        "  gs2.update(top=1-2/3-0.05, bottom=0, left=0.15, right=0.85, wspace=0.0)\n",
        "  \n",
        "  ax = plt.subplot(gs2[0, 0])\n",
        "  ax.axis('off')\n",
        "  nu = 0.01/np.pi\n",
        "  s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x + %.6f u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & ' % (nu)\n",
        "  s2 = r'$u_t + %.3f u u_x + %.6f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "  s3 = r'Identified PDE (1\\% noise) & '\n",
        "  s4 = r'$u_t + %.3f u u_x + %.6f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "  s5 = r'\\end{tabular}$'\n",
        "  s = s1+s2+s3+s4+s5\n",
        "  ax.text(-0.1,0.2,s)\n",
        "  plt.show()\n",
        "\n",
        "def plot_ide_cont_results(X_star, u_pred, X_u_train, u_train,\n",
        "  Exact_u, X, T, x, t, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy):\n",
        "    fig, ax = newfig(1.0, 1.4)\n",
        "    ax.axis('off')\n",
        "\n",
        "    U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "    \n",
        "    ####### Row 0: u(t,x) ##################    \n",
        "    gs0 = gridspec.GridSpec(1, 2)\n",
        "    gs0.update(top=1-0.06, bottom=1-1.0/3.0+0.06, left=0.15, right=0.85, wspace=0)\n",
        "    ax = plt.subplot(gs0[:, :])\n",
        "    \n",
        "    h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    \n",
        "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 2, clip_on = False)\n",
        "    \n",
        "    line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "    ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "    ax.set_xlabel('$t$')\n",
        "    ax.set_ylabel('$x$')\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(1.0, -0.125), ncol=5, frameon=False)\n",
        "    ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "    \n",
        "    ####### Row 1: u(t,x) slices ##################    \n",
        "    gs1 = gridspec.GridSpec(1, 3)\n",
        "    gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 0])\n",
        "    ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')\n",
        "    ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')    \n",
        "    ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 1])\n",
        "    ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "    ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 2])\n",
        "    ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "    ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])    \n",
        "    ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "    \n",
        "    ####### Row 3: Identified PDE ##################    \n",
        "    gs2 = gridspec.GridSpec(1, 3)\n",
        "    gs2.update(top=1.0-2.0/3.0, bottom=0, left=0.0, right=1.0, wspace=0.0)\n",
        "    \n",
        "    ax = plt.subplot(gs2[:, :])\n",
        "    ax.axis('off')\n",
        "    s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x - 0.0031831 u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & '\n",
        "    s2 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "    s3 = r'Identified PDE (1\\% noise) & '\n",
        "    s4 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s5 = r'\\end{tabular}$'\n",
        "    s = s1+s2+s3+s4+s5\n",
        "    ax.text(0.1,0.1,s)\n",
        "    plt.show()\n",
        "    # savefig('./figures/Burgers_identification')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7Azv7DZp0M-"
      },
      "source": [
        "custom_lbfgs.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjvMe1Avpvh9",
        "lines_to_next_cell": 0
      },
      "source": [
        "# Adapted from https://github.com/yaroslavvb/stuff/blob/master/eager_lbfgs/eager_lbfgs.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Time tracking functions\n",
        "global_time_list = []\n",
        "global_last_time = 0\n",
        "def reset_time():\n",
        "  global global_time_list, global_last_time\n",
        "  global_time_list = []\n",
        "  global_last_time = time.perf_counter()\n",
        "  \n",
        "def record_time():\n",
        "  global global_last_time, global_time_list\n",
        "  new_time = time.perf_counter()\n",
        "  global_time_list.append(new_time - global_last_time)\n",
        "  global_last_time = time.perf_counter()\n",
        "  #print(\"step: %.2f\"%(global_time_list[-1]*1000))\n",
        "\n",
        "def last_time():\n",
        "  \"\"\"Returns last interval records in millis.\"\"\"\n",
        "  global global_last_time, global_time_list\n",
        "  if global_time_list:\n",
        "    return 1000 * global_time_list[-1]\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def dot(a, b):\n",
        "  \"\"\"Dot product function since TensorFlow doesn't have one.\"\"\"\n",
        "  return tf.reduce_sum(a*b)\n",
        "\n",
        "def verbose_func(s):\n",
        "  print(s)\n",
        "\n",
        "final_loss = None\n",
        "times = []\n",
        "def lbfgs(opfunc, x, config, state, do_verbose, log_fn):\n",
        "  \"\"\"port of lbfgs.lua, using TensorFlow eager mode.\n",
        "  \"\"\"\n",
        "\n",
        "  if config.maxIter == 0:\n",
        "    return\n",
        "\n",
        "  global final_loss, times\n",
        "  \n",
        "  maxIter = config.maxIter\n",
        "  maxEval = config.maxEval or maxIter*1.25\n",
        "  tolFun = config.tolFun or 1e-5\n",
        "  tolX = config.tolX or 1e-19\n",
        "  nCorrection = config.nCorrection or 100\n",
        "  lineSearch = config.lineSearch\n",
        "  lineSearchOpts = config.lineSearchOptions\n",
        "  learningRate = config.learningRate or 1\n",
        "  isverbose = config.verbose or False\n",
        "\n",
        "  # verbose function\n",
        "  if isverbose:\n",
        "    verbose = verbose_func\n",
        "  else:\n",
        "    verbose = lambda x: None\n",
        "\n",
        "    # evaluate initial f(x) and df/dx\n",
        "  f, g = opfunc(x)\n",
        "\n",
        "  f_hist = [f]\n",
        "  currentFuncEval = 1\n",
        "  state.funcEval = state.funcEval + 1\n",
        "  p = g.shape[0]\n",
        "\n",
        "  # check optimality of initial point\n",
        "  tmp1 = tf.abs(g)\n",
        "  if tf.reduce_sum(tmp1) <= tolFun:\n",
        "    verbose(\"optimality condition below tolFun\")\n",
        "    return x, f_hist\n",
        "\n",
        "  # optimize for a max of maxIter iterations\n",
        "  nIter = 0\n",
        "  times = []\n",
        "  while nIter < maxIter:\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # keep track of nb of iterations\n",
        "    nIter = nIter + 1\n",
        "    state.nIter = state.nIter + 1\n",
        "\n",
        "    ############################################################\n",
        "    ## compute gradient descent direction\n",
        "    ############################################################\n",
        "    if state.nIter == 1:\n",
        "      d = -g\n",
        "      old_dirs = []\n",
        "      old_stps = []\n",
        "      Hdiag = 1\n",
        "    else:\n",
        "      # do lbfgs update (update memory)\n",
        "      y = g - g_old\n",
        "      s = d*t\n",
        "      ys = dot(y, s)\n",
        "      \n",
        "      if ys > 1e-10:\n",
        "        # updating memory\n",
        "        if len(old_dirs) == nCorrection:\n",
        "          # shift history by one (limited-memory)\n",
        "          del old_dirs[0]\n",
        "          del old_stps[0]\n",
        "\n",
        "        # store new direction/step\n",
        "        old_dirs.append(s)\n",
        "        old_stps.append(y)\n",
        "\n",
        "        # update scale of initial Hessian approximation\n",
        "        Hdiag = ys/dot(y, y)\n",
        "\n",
        "      # compute the approximate (L-BFGS) inverse Hessian \n",
        "      # multiplied by the gradient\n",
        "      k = len(old_dirs)\n",
        "\n",
        "      # need to be accessed element-by-element, so don't re-type tensor:\n",
        "      ro = [0]*nCorrection\n",
        "      for i in range(k):\n",
        "        ro[i] = 1/dot(old_stps[i], old_dirs[i])\n",
        "        \n",
        "\n",
        "      # iteration in L-BFGS loop collapsed to use just one buffer\n",
        "      # need to be accessed element-by-element, so don't re-type tensor:\n",
        "      al = [0]*nCorrection\n",
        "\n",
        "      q = -g\n",
        "      for i in range(k-1, -1, -1):\n",
        "        al[i] = dot(old_dirs[i], q) * ro[i]\n",
        "        q = q - al[i]*old_stps[i]\n",
        "\n",
        "      # multiply by initial Hessian\n",
        "      r = q*Hdiag\n",
        "      for i in range(k):\n",
        "        be_i = dot(old_stps[i], r) * ro[i]\n",
        "        r += (al[i]-be_i)*old_dirs[i]\n",
        "        \n",
        "      d = r\n",
        "      # final direction is in r/d (same object)\n",
        "\n",
        "    g_old = g\n",
        "    f_old = f\n",
        "    \n",
        "    ############################################################\n",
        "    ## compute step length\n",
        "    ############################################################\n",
        "    # directional derivative\n",
        "    gtd = dot(g, d)\n",
        "\n",
        "    # check that progress can be made along that direction\n",
        "    if gtd > -tolX:\n",
        "      verbose(\"Can not make progress along direction.\")\n",
        "      break\n",
        "\n",
        "    # reset initial guess for step size\n",
        "    if state.nIter == 1:\n",
        "      tmp1 = tf.abs(g)\n",
        "      t = min(1, 1/tf.reduce_sum(tmp1))\n",
        "    else:\n",
        "      t = learningRate\n",
        "\n",
        "\n",
        "    # optional line search: user function\n",
        "    lsFuncEval = 0\n",
        "    if lineSearch and isinstance(lineSearch) == types.FunctionType:\n",
        "      # perform line search, using user function\n",
        "      f,g,x,t,lsFuncEval = lineSearch(opfunc,x,t,d,f,g,gtd,lineSearchOpts)\n",
        "      f_hist.append(f)\n",
        "    else:\n",
        "      # no line search, simply move with fixed-step\n",
        "      x += t*d\n",
        "      \n",
        "      if nIter != maxIter:\n",
        "        # re-evaluate function only if not in last iteration\n",
        "        # the reason we do this: in a stochastic setting,\n",
        "        # no use to re-evaluate that function here\n",
        "        f, g = opfunc(x)\n",
        "        lsFuncEval = 1\n",
        "        f_hist.append(f)\n",
        "\n",
        "\n",
        "    # update func eval\n",
        "    currentFuncEval = currentFuncEval + lsFuncEval\n",
        "    state.funcEval = state.funcEval + lsFuncEval\n",
        "\n",
        "    ############################################################\n",
        "    ## check conditions\n",
        "    ############################################################\n",
        "    if nIter == maxIter:\n",
        "      break\n",
        "\n",
        "    if currentFuncEval >= maxEval:\n",
        "      # max nb of function evals\n",
        "      verbose('max nb of function evals')\n",
        "      break\n",
        "\n",
        "    tmp1 = tf.abs(g)\n",
        "    if tf.reduce_sum(tmp1) <=tolFun:\n",
        "      # check optimality\n",
        "      verbose('optimality condition below tolFun')\n",
        "      break\n",
        "    \n",
        "    tmp1 = tf.abs(d*t)\n",
        "    if tf.reduce_sum(tmp1) <= tolX:\n",
        "      # step size below tolX\n",
        "      verbose('step size below tolX')\n",
        "      break\n",
        "\n",
        "    if tf.abs(f-f_old) < tolX:\n",
        "      # function value changing less than tolX\n",
        "      verbose('function value changing less than tolX'+str(tf.abs(f-f_old)))\n",
        "      break\n",
        "\n",
        "    if do_verbose:\n",
        "      log_fn(nIter, f.numpy(), True)\n",
        "      #print(\"Step %3d loss %6.5f msec %6.3f\"%(nIter, f.numpy(), last_time()))\n",
        "      record_time()\n",
        "      times.append(last_time())\n",
        "\n",
        "    if nIter == maxIter - 1:\n",
        "      final_loss = f.numpy()\n",
        "\n",
        "\n",
        "  # save state\n",
        "  state.old_dirs = old_dirs\n",
        "  state.old_stps = old_stps\n",
        "  state.Hdiag = Hdiag\n",
        "  state.g_old = g_old\n",
        "  state.f_old = f_old\n",
        "  state.t = t\n",
        "  state.d = d\n",
        "\n",
        "  return x, f_hist, currentFuncEval\n",
        "\n",
        "# dummy/Struct gives Lua-like struct object with 0 defaults\n",
        "class dummy(object):\n",
        "  pass\n",
        "\n",
        "class Struct(dummy):\n",
        "  def __getattribute__(self, key):\n",
        "    if key == '__dict__':\n",
        "      return super(dummy, self).__getattribute__('__dict__')\n",
        "    return self.__dict__.get(key, 0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOT-E8C4oAJN"
      },
      "source": [
        "# 1. Continuous Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qrt3ECzcLHp"
      },
      "source": [
        "$$u_t + u u_x - \\nu u_{xx} = 0$$\n",
        "\n",
        "With $x \\in [-1,1],\\quad t \\in [0,1],\\quad \\nu = (0.01/\\pi)$.\n",
        "\n",
        "And $u(0,x) = -\\sin(\\pi x),\\quad u(t,-1) = u(t,1) = 0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8CHqrpafela"
      },
      "source": [
        "Approximating $u(t,x)$ with a deep NN, we define the PINN:\n",
        "$$f := u_t + u u_x - \\nu u_{xx}.$$\n",
        "\n",
        "We train the shared parameters between the deep NN and the PINN minimizing the loss:\n",
        "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_f}|f(t_f^i,x_f^i)|^2,$$\n",
        "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ and $\\{t_f^i, x_f^i\\}_{i=1}^{N_f}$ respectively the initial/boundary data on $u(t,x)$ and collocations points for $f(t,x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Ko6L87J2v_"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwWhiecUqbAo",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Data size on the solution u\n",
        "N_u = 50\n",
        "# Collocation points size, where we’ll check for f = 0\n",
        "N_f = 10000\n",
        "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
        "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "tf_epochs = 100\n",
        "tf_optimizer = tf.keras.optimizers.Adam(\n",
        "  learning_rate=0.1,\n",
        "  beta_1=0.99,\n",
        "  epsilon=1e-1)\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "nt_epochs = 2000\n",
        "nt_config = Struct()\n",
        "nt_config.learningRate = 0.8\n",
        "nt_config.maxIter = nt_epochs\n",
        "nt_config.nCorrection = 50\n",
        "nt_config.tolFun = 1.0 * np.finfo(float).eps\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkimJNtepkKi"
      },
      "source": [
        "## PINN class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3wUjV9oe7V9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVm9UCvvlyY_"
      },
      "source": [
        "\n",
        "class PhysicsInformedNN(object):\n",
        "  def __init__(self, layers, optimizer, logger, X_f, ub, lb, nu):\n",
        "    # Descriptive Keras model [2, 20, …, 20, 1]\n",
        "    self.u_model = tf.keras.Sequential()\n",
        "    self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    self.u_model.add(tf.keras.layers.Lambda(\n",
        "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:]:\n",
        "        self.u_model.add(tf.keras.layers.Dense(\n",
        "          width, activation=tf.nn.tanh,\n",
        "          kernel_initializer='glorot_normal'))\n",
        "\n",
        "    # Computing the sizes of weights/biases for future decomposition\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    for i, width in enumerate(layers):\n",
        "      if i != 1:\n",
        "        self.sizes_w.append(int(width * layers[1]))\n",
        "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "    self.nu = nu\n",
        "    self.optimizer = optimizer\n",
        "    self.logger = logger\n",
        "\n",
        "    self.dtype = tf.float32\n",
        "\n",
        "    # Separating the collocation coordinates\n",
        "    self.x_f = tf.convert_to_tensor(X_f[:, 0:1], dtype=self.dtype)\n",
        "    self.t_f = tf.convert_to_tensor(X_f[:, 1:2], dtype=self.dtype)\n",
        "    \n",
        "  # Defining custom loss\n",
        "  def __loss(self, u, u_pred):\n",
        "    f_pred = self.f_model()\n",
        "    return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
        "      tf.reduce_mean(tf.square(f_pred))\n",
        "\n",
        "  def __grad(self, X, u):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.__loss(u, self.u_model(X))\n",
        "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "\n",
        "  def __wrap_training_variables(self):\n",
        "    var = self.u_model.trainable_variables\n",
        "    return var\n",
        "\n",
        "  # The actual PINN\n",
        "  def f_model(self):\n",
        "    # Using the new GradientTape paradigm of TF2.0,\n",
        "    # which keeps track of operations to get the gradient at runtime\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Watching the two inputs we’ll need later, x and t\n",
        "      tape.watch(self.x_f)\n",
        "      tape.watch(self.t_f)\n",
        "      # Packing together the inputs\n",
        "      X_f = tf.stack([self.x_f[:,0], self.t_f[:,0]], axis=1)\n",
        "\n",
        "      # Getting the prediction\n",
        "      u = self.u_model(X_f)\n",
        "      # Deriving INSIDE the tape (since we’ll need the x derivative of this later, u_xx)\n",
        "      u_x = tape.gradient(u, self.x_f)\n",
        "    \n",
        "    # Getting the other derivatives\n",
        "    u_xx = tape.gradient(u_x, self.x_f)\n",
        "    u_t = tape.gradient(u, self.t_f)\n",
        "\n",
        "    # Letting the tape go\n",
        "    del tape\n",
        "\n",
        "    nu = self.get_params(numpy=True)\n",
        "\n",
        "    # Buidling the PINNs\n",
        "    return u_t + u*u_x - nu*u_xx\n",
        "\n",
        "  def get_params(self, numpy=False):\n",
        "    return self.nu\n",
        "\n",
        "  def get_weights(self):\n",
        "    w = []\n",
        "    for layer in self.u_model.layers[1:]:\n",
        "      weights_biases = layer.get_weights()\n",
        "      weights = weights_biases[0].flatten()\n",
        "      biases = weights_biases[1]\n",
        "      w.extend(weights)\n",
        "      w.extend(biases)\n",
        "    return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.u_model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "\n",
        "  def summary(self):\n",
        "    return self.u_model.summary()\n",
        "\n",
        "  # The training function\n",
        "  def fit(self, X_u, u, tf_epochs=5000, nt_config=Struct()):\n",
        "    self.logger.log_train_start(self)\n",
        "\n",
        "    # Creating the tensors\n",
        "    X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
        "    u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
        "\n",
        "    self.logger.log_train_opt(\"Adam\")\n",
        "    for epoch in range(tf_epochs):\n",
        "      # Optimization step\n",
        "      loss_value, grads = self.__grad(X_u, u)\n",
        "      self.optimizer.apply_gradients(zip(grads, self.__wrap_training_variables()))\n",
        "      self.logger.log_train_epoch(epoch, loss_value)\n",
        "    \n",
        "    self.logger.log_train_opt(\"LBFGS\")\n",
        "    def loss_and_flat_grad(w):\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        loss_value = self.__loss(u, self.u_model(X_u))\n",
        "      grad = tape.gradient(loss_value, self.u_model.trainable_variables)\n",
        "      grad_flat = []\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat =  tf.concat(grad_flat, 0)\n",
        "      return loss_value, grad_flat\n",
        "    # tfp.optimizer.lbfgs_minimize(\n",
        "    #   loss_and_flat_grad,\n",
        "    #   initial_position=self.get_weights(),\n",
        "    #   num_correction_pairs=nt_config.nCorrection,\n",
        "    #   max_iterations=nt_config.maxIter,\n",
        "    #   f_relative_tolerance=nt_config.tolFun,\n",
        "    #   tolerance=nt_config.tolFun,\n",
        "    #   parallel_iterations=6)\n",
        "    lbfgs(loss_and_flat_grad,\n",
        "      self.get_weights(),\n",
        "      nt_config, Struct(), True,\n",
        "      lambda epoch, loss, is_iter:\n",
        "        self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\n",
        "\n",
        "    self.logger.log_train_end(tf_epochs + nt_config.maxIter)\n",
        "\n",
        "  def predict(self, X_star):\n",
        "    u_star = self.u_model(X_star)\n",
        "    f_star = self.f_model()\n",
        "    return u_star, f_star"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FzMd65dpoHo"
      },
      "source": [
        "## Training and plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEKkpHvApf46",
        "lines_to_next_cell": 2,
        "outputId": "486c989c-0211-4c30-8995-75bd90af12f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Getting the data\n",
        "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "  X_u_train, u_train, X_f, ub, lb = prep_data(path, N_u, N_f, noise=0.0)\n",
        "\n",
        "# Creating the model and training\n",
        "logger = Logger(frequency=10)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, X_f, ub, lb, nu=0.01/np.pi)\n",
        "def error():\n",
        "  u_pred, _ = pinn.predict(X_star)\n",
        "  return np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_pred, f_pred = pinn.predict(X_star)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n",
            "Eager execution: True\n",
            "WARNING:tensorflow:From <ipython-input-9-2616730e37e2>:131: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU-accerelated: True\n",
            "\n",
            "Training started\n",
            "================\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20)                60        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 3,021\n",
            "Trainable params: 3,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "—— Starting Adam optimization ——\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "tf_epoch =      0  elapsed = 00:01  loss = 2.9103e-01  error = 8.8958e-01  \n",
            "tf_epoch =     10  elapsed = 00:02  loss = 2.1053e-01  error = 7.8298e-01  \n",
            "tf_epoch =     20  elapsed = 00:02  loss = 1.8826e-01  error = 6.7527e-01  \n",
            "tf_epoch =     30  elapsed = 00:03  loss = 1.6335e-01  error = 6.6386e-01  \n",
            "tf_epoch =     40  elapsed = 00:03  loss = 1.5234e-01  error = 6.1549e-01  \n",
            "tf_epoch =     50  elapsed = 00:03  loss = 1.5271e-01  error = 5.5059e-01  \n",
            "tf_epoch =     60  elapsed = 00:04  loss = 1.5121e-01  error = 6.1824e-01  \n",
            "tf_epoch =     70  elapsed = 00:04  loss = 1.4983e-01  error = 5.9295e-01  \n",
            "tf_epoch =     80  elapsed = 00:05  loss = 1.4985e-01  error = 6.3547e-01  \n",
            "tf_epoch =     90  elapsed = 00:05  loss = 1.4213e-01  error = 5.9022e-01  \n",
            "—— Starting LBFGS optimization ——\n",
            "nt_epoch =     10  elapsed = 00:06  loss = 1.0505e-01  error = 5.0906e-01  \n",
            "nt_epoch =     20  elapsed = 00:07  loss = 8.8612e-02  error = 5.1689e-01  \n",
            "nt_epoch =     30  elapsed = 00:07  loss = 7.3399e-02  error = 4.9323e-01  \n",
            "nt_epoch =     40  elapsed = 00:08  loss = 6.4589e-02  error = 4.6729e-01  \n",
            "nt_epoch =     50  elapsed = 00:09  loss = 6.1807e-02  error = 4.5987e-01  \n",
            "nt_epoch =     60  elapsed = 00:10  loss = 5.7670e-02  error = 4.4943e-01  \n",
            "nt_epoch =     70  elapsed = 00:10  loss = 5.4589e-02  error = 4.4200e-01  \n",
            "nt_epoch =     80  elapsed = 00:11  loss = 4.9497e-02  error = 4.2514e-01  \n",
            "nt_epoch =     90  elapsed = 00:12  loss = 4.6997e-02  error = 4.0958e-01  \n",
            "==================\n",
            "Training finished (epoch 2100): duration = 00:13  error = 1.9442e+00  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf1QXaK5PlUh",
        "lines_to_next_cell": 0,
        "outputId": "cb02f48c-04f4-463b-bc3d-45c1974dc703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "plot_inf_cont_results(X_star, u_pred.numpy().flatten(), X_u_train, u_train,\n",
        "  Exact_u, X, T, x, t)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 388.543x264.146 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-Dt42ItxAqr"
      },
      "source": [
        "# 2. Discrete Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1oPFjYDxAqs"
      },
      "source": [
        "$$u_t + u u_x - \\nu u_{xx} = 0$$\n",
        "\n",
        "With $x \\in [-1,1],\\quad t \\in [0,1],\\quad \\nu = (0.01/\\pi)$.\n",
        "\n",
        "And $u(0,x) = -\\sin(\\pi x),\\quad u(t,-1) = u(t,1) = 0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4z7cQz_xAqt"
      },
      "source": [
        "Approximating $u(t,x)$ with a deep NN, we define the PINN: (TODO)\n",
        "$$f := u_t + u u_x - \\nu u_{xx}.$$\n",
        "\n",
        "We train the shared parameters between the deep NN and the PINN minimizing the loss: (TODO)\n",
        "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_f}|f(t_f^i,x_f^i)|^2,$$\n",
        "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ and $\\{t_f^i, x_f^i\\}_{i=1}^{N_f}$ respectively the initial/boundary data on $u(t,x)$ and collocations points for $f(t,x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGd5zVtoxAqt"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKrkV1ChxAqu",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Data size on initial condition on u\n",
        "N_n = 250\n",
        "# Number of RK stages\n",
        "q = 500\n",
        "# DeepNN topology (1-sized input [x], 3 hidden layer of 50-width, q+1-sized output [u_1^n(x), ..., u_{q+1}^n(x)]\n",
        "layers = [1, 50, 50, 50, q + 1]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "tf_epochs = 200\n",
        "tf_optimizer = tf.keras.optimizers.Adam(\n",
        "  lr=0.001,\n",
        "  beta_1=0.9,\n",
        "  beta_2=0.999,\n",
        "  epsilon=1e-08)\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "nt_epochs = 1000\n",
        "nt_config = Struct()\n",
        "nt_config.learningRate = 0.8\n",
        "nt_config.maxIter = nt_epochs\n",
        "nt_config.nCorrection = 50\n",
        "nt_config.tolFun = 1.0 * np.finfo(float).eps\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXtJ5GiaxAqw"
      },
      "source": [
        "## PINN class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiPSoTyPxAqw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2acHqmorxAqx"
      },
      "source": [
        "\n",
        "class PhysicsInformedNN(object):\n",
        "  def __init__(self, layers, optimizer, logger, dt, x_1, lb, ub, nu, q, IRK_weights, IRK_times):\n",
        "    self.lb = lb\n",
        "    self.ub = ub\n",
        "    self.nu = nu\n",
        "\n",
        "    self.dt = dt\n",
        "\n",
        "    self.q = max(q,1)\n",
        "    self.IRK_weights = IRK_weights\n",
        "    self.IRK_times = IRK_times\n",
        "\n",
        "    # Descriptive Keras model [2, 50, …, 50, q+1]\n",
        "    self.U_1_model = tf.keras.Sequential()\n",
        "    self.U_1_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    self.U_1_model.add(tf.keras.layers.Lambda(\n",
        "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:]:\n",
        "        self.U_1_model.add(tf.keras.layers.Dense(\n",
        "          width, activation=tf.nn.tanh,\n",
        "          kernel_initializer='glorot_normal'))\n",
        "\n",
        "    # Computing the sizes of weights/biases for future decomposition\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    for i, width in enumerate(layers):\n",
        "      if i != 1:\n",
        "        self.sizes_w.append(int(width * layers[1]))\n",
        "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "    self.dtype = tf.float32\n",
        "\n",
        "    self.x_1 = tf.convert_to_tensor(x_1, dtype=self.dtype)\n",
        "\n",
        "    self.optimizer = optimizer\n",
        "    self.logger = logger\n",
        "\n",
        "  def U_0_model(self, x):\n",
        "    # Using the new GradientTape paradigm of TF2.0,\n",
        "    # which keeps track of operations to get the gradient at runtime\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Watching the two inputs we’ll need later, x and t\n",
        "      tape.watch(x)\n",
        "      tape.watch(self.dummy_x0_tf)\n",
        "\n",
        "      # Getting the prediction, and removing the last item (q+1)\n",
        "      U_1 = self.U_1_model(x) # shape=(len(x), q+1)\n",
        "      U = U_1[:, :-1] # shape=(len(x), q)\n",
        "\n",
        "      # Deriving INSIDE the tape (2-step-dummy grad technique because U is a mat)\n",
        "      g_U = tape.gradient(U, x, output_gradients=self.dummy_x0_tf)\n",
        "      U_x = tape.gradient(g_U, self.dummy_x0_tf)\n",
        "      g_U_x = tape.gradient(U_x, x, output_gradients=self.dummy_x0_tf)\n",
        "    \n",
        "    # Doing the last one outside the with, to optimize performance\n",
        "    # Impossible to do for the earlier grad, because they’re needed after\n",
        "    U_xx = tape.gradient(g_U_x, self.dummy_x0_tf)\n",
        "\n",
        "    # Letting the tape go\n",
        "    del tape\n",
        "\n",
        "    # Buidling the PINNs, shape = (len(x), q+1), IRK shape = (q, q+1)\n",
        "    nu = self.get_params(numpy=True)\n",
        "    N = U*U_x - nu*U_xx # shape=(len(x), q)\n",
        "    return U_1 + self.dt*tf.matmul(N, self.IRK_weights.T)\n",
        "\n",
        "  # Defining custom loss\n",
        "  def __loss(self, u_0, u_0_pred):\n",
        "    u_1_pred = self.U_1_model(self.x_1)\n",
        "    return tf.reduce_sum(tf.square(u_0_pred - u_0)) + \\\n",
        "      tf.reduce_sum(tf.square(u_1_pred))\n",
        "\n",
        "  def __grad(self, x_0, u_0):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.__loss(u_0, self.U_0_model(x_0))\n",
        "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "\n",
        "  def __wrap_training_variables(self):\n",
        "    var = self.U_1_model.trainable_variables\n",
        "    return var\n",
        "\n",
        "  def get_weights(self):\n",
        "    w = []\n",
        "    for layer in self.U_1_model.layers[1:]:\n",
        "      weights_biases = layer.get_weights()\n",
        "      weights = weights_biases[0].flatten()\n",
        "      biases = weights_biases[1]\n",
        "      w.extend(weights)\n",
        "      w.extend(biases)\n",
        "    return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.U_1_model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "\n",
        "  def get_params(self, numpy=False):\n",
        "    return self.nu\n",
        "\n",
        "  def summary(self):\n",
        "    return self.U_1_model.summary()\n",
        "\n",
        "  # The training function\n",
        "  def fit(self, x_0, u_0, tf_epochs, nt_config):\n",
        "    self.logger.log_train_start(self)\n",
        "\n",
        "    # Creating the tensors\n",
        "    x_0 = tf.convert_to_tensor(x_0, dtype=self.dtype)\n",
        "    u_0 = tf.convert_to_tensor(u_0, dtype=self.dtype)\n",
        "\n",
        "    # Creating dummy tensors for the gradients\n",
        "    self.dummy_x0_tf = tf.ones([x_0.shape[0], self.q], dtype=self.dtype)\n",
        "\n",
        "    self.logger.log_train_opt(\"Adam\")\n",
        "    for epoch in range(tf_epochs):\n",
        "      # Optimization step\n",
        "      loss_value, grads = self.__grad(x_0, u_0)\n",
        "      self.optimizer.apply_gradients(\n",
        "        zip(grads, self.__wrap_training_variables()))\n",
        "      self.logger.log_train_epoch(epoch, loss_value)\n",
        "\n",
        "    self.logger.log_train_opt(\"LBFGS\")\n",
        "    def loss_and_flat_grad(w):\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        loss_value = self.__loss(u_0, self.U_0_model(x_0))\n",
        "      grad = tape.gradient(loss_value, self.U_1_model.trainable_variables)\n",
        "      grad_flat = []\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat =  tf.concat(grad_flat, 0)\n",
        "      return loss_value, grad_flat\n",
        "    # tfp.optimizer.lbfgs_minimize(\n",
        "    #   loss_and_flat_grad,\n",
        "    #   initial_position=self.get_weights(),\n",
        "    #   num_correction_pairs=nt_config.nCorrection,\n",
        "    #   max_iterations=nt_config.maxIter,\n",
        "    #   f_relative_tolerance=nt_config.tolFun,\n",
        "    #   tolerance=nt_config.tolFun,\n",
        "    #   parallel_iterations=6)\n",
        "    lbfgs(loss_and_flat_grad,\n",
        "      self.get_weights(),\n",
        "      nt_config, Struct(), True,\n",
        "      lambda epoch, loss, is_iter:\n",
        "        self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\n",
        "    \n",
        "    self.logger.log_train_end(tf_epochs)\n",
        "\n",
        "  def predict(self, x_star):\n",
        "    u_star = self.U_1_model(x_star)[:, -1]\n",
        "    return u_star"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIq8U_a_xAqy"
      },
      "source": [
        "## Training and plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ICbcZhxAqz",
        "outputId": "86ff587f-e29d-43b9-a20c-6b7fdb11161e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Setup\n",
        "lb = np.array([-1.0])\n",
        "ub = np.array([1.0])\n",
        "idx_t_0 = 10\n",
        "idx_t_1 = 90\n",
        "nu = 0.01/np.pi\n",
        "\n",
        "# Getting the data\n",
        "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
        "x, t, dt, \\\n",
        "  Exact_u, x_0, u_0, x_1, x_star, u_star, \\\n",
        "  IRK_weights, IRK_times = prep_data(path, N_n=N_n, q=q, lb=lb, ub=ub, noise=0.0, idx_t_0=idx_t_0, idx_t_1=idx_t_1)\n",
        "\n",
        "# Creating the model and training\n",
        "logger = Logger(frequency=10)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, dt, x_1, lb, ub, nu, q, IRK_weights, IRK_times)\n",
        "def error():\n",
        "  u_pred = pinn.predict(x_star)\n",
        "  return np.linalg.norm(u_pred - u_star, 2) / np.linalg.norm(u_star, 2)\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(x_0, u_0, tf_epochs, nt_config)\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_1_pred = pinn.predict(x_star)\n",
        "\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_1_pred = pinn.predict(x_star)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n",
            "Eager execution: True\n",
            "GPU-accerelated: True\n",
            "\n",
            "Training started\n",
            "================\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_1 (Lambda)            (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 501)               25551     \n",
            "=================================================================\n",
            "Total params: 30,751\n",
            "Trainable params: 30,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "—— Starting Adam optimization ——\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "tf_epoch =      0  elapsed = 00:00  loss = 6.1188e+04  error = 9.9183e-01  \n",
            "tf_epoch =     10  elapsed = 00:00  loss = 5.2999e+04  error = 9.1168e-01  \n",
            "tf_epoch =     20  elapsed = 00:00  loss = 4.0422e+04  error = 8.3942e-01  \n",
            "tf_epoch =     30  elapsed = 00:01  loss = 3.0798e+04  error = 1.0075e+00  \n",
            "tf_epoch =     40  elapsed = 00:01  loss = 2.6585e+04  error = 1.2057e+00  \n",
            "tf_epoch =     50  elapsed = 00:01  loss = 2.3989e+04  error = 1.3011e+00  \n",
            "tf_epoch =     60  elapsed = 00:01  loss = 2.1985e+04  error = 1.3448e+00  \n",
            "tf_epoch =     70  elapsed = 00:02  loss = 2.0261e+04  error = 1.3670e+00  \n",
            "tf_epoch =     80  elapsed = 00:02  loss = 1.8731e+04  error = 1.3788e+00  \n",
            "tf_epoch =     90  elapsed = 00:02  loss = 1.7442e+04  error = 1.3852e+00  \n",
            "tf_epoch =    100  elapsed = 00:03  loss = 1.6428e+04  error = 1.3889e+00  \n",
            "tf_epoch =    110  elapsed = 00:03  loss = 1.5687e+04  error = 1.3913e+00  \n",
            "tf_epoch =    120  elapsed = 00:03  loss = 1.5193e+04  error = 1.3929e+00  \n",
            "tf_epoch =    130  elapsed = 00:04  loss = 1.4885e+04  error = 1.3941e+00  \n",
            "tf_epoch =    140  elapsed = 00:04  loss = 1.4671e+04  error = 1.3951e+00  \n",
            "tf_epoch =    150  elapsed = 00:04  loss = 1.4462e+04  error = 1.3959e+00  \n",
            "tf_epoch =    160  elapsed = 00:04  loss = 1.4274e+04  error = 1.3966e+00  \n",
            "tf_epoch =    170  elapsed = 00:05  loss = 1.4054e+04  error = 1.3972e+00  \n",
            "tf_epoch =    180  elapsed = 00:05  loss = 1.3774e+04  error = 1.3978e+00  \n",
            "tf_epoch =    190  elapsed = 00:05  loss = 1.3375e+04  error = 1.3985e+00  \n",
            "—— Starting LBFGS optimization ——\n",
            "nt_epoch =     10  elapsed = 00:06  loss = 1.0259e+04  error = 1.3989e+00  \n",
            "nt_epoch =     20  elapsed = 00:06  loss = 7.9967e+03  error = 1.3987e+00  \n",
            "nt_epoch =     30  elapsed = 00:07  loss = 6.5924e+03  error = 1.3955e+00  \n",
            "nt_epoch =     40  elapsed = 00:07  loss = 5.3154e+03  error = 1.3828e+00  \n",
            "nt_epoch =     50  elapsed = 00:08  loss = 4.3656e+03  error = 1.3262e+00  \n",
            "nt_epoch =     60  elapsed = 00:09  loss = 3.2430e+03  error = 5.5628e-01  \n",
            "nt_epoch =     70  elapsed = 00:09  loss = 2.3788e+03  error = 2.9506e-01  \n",
            "nt_epoch =     80  elapsed = 00:10  loss = 1.5826e+03  error = 2.0132e-01  \n",
            "nt_epoch =     90  elapsed = 00:10  loss = 1.0608e+03  error = 2.6694e-01  \n",
            "nt_epoch =    100  elapsed = 00:11  loss = 6.1446e+02  error = 2.3924e-01  \n",
            "nt_epoch =    110  elapsed = 00:11  loss = 4.5490e+02  error = 1.8508e-01  \n",
            "nt_epoch =    120  elapsed = 00:12  loss = 3.8912e+02  error = 1.7763e-01  \n",
            "nt_epoch =    130  elapsed = 00:13  loss = 3.2107e+02  error = 1.5215e-01  \n",
            "nt_epoch =    140  elapsed = 00:13  loss = 2.0589e+02  error = 1.4637e-01  \n",
            "nt_epoch =    150  elapsed = 00:14  loss = 1.4495e+02  error = 1.5221e-01  \n",
            "nt_epoch =    160  elapsed = 00:14  loss = 1.1752e+02  error = 1.4089e-01  \n",
            "nt_epoch =    170  elapsed = 00:15  loss = 1.0353e+02  error = 1.2740e-01  \n",
            "nt_epoch =    180  elapsed = 00:15  loss = 9.2245e+01  error = 1.1897e-01  \n",
            "nt_epoch =    190  elapsed = 00:16  loss = 8.0327e+01  error = 1.1045e-01  \n",
            "nt_epoch =    200  elapsed = 00:17  loss = 7.1264e+01  error = 9.9046e-02  \n",
            "nt_epoch =    210  elapsed = 00:17  loss = 6.5959e+01  error = 9.5547e-02  \n",
            "nt_epoch =    220  elapsed = 00:18  loss = 6.1504e+01  error = 9.3695e-02  \n",
            "nt_epoch =    230  elapsed = 00:18  loss = 5.7132e+01  error = 8.8766e-02  \n",
            "nt_epoch =    240  elapsed = 00:19  loss = 5.2151e+01  error = 8.0482e-02  \n",
            "nt_epoch =    250  elapsed = 00:19  loss = 4.9175e+01  error = 7.7340e-02  \n",
            "nt_epoch =    260  elapsed = 00:20  loss = 4.5669e+01  error = 7.6202e-02  \n",
            "nt_epoch =    270  elapsed = 00:21  loss = 4.2506e+01  error = 7.1088e-02  \n",
            "nt_epoch =    280  elapsed = 00:21  loss = 4.0089e+01  error = 6.8674e-02  \n",
            "nt_epoch =    290  elapsed = 00:22  loss = 3.6840e+01  error = 6.7125e-02  \n",
            "nt_epoch =    300  elapsed = 00:22  loss = 3.4765e+01  error = 6.7175e-02  \n",
            "nt_epoch =    310  elapsed = 00:23  loss = 3.2893e+01  error = 6.4406e-02  \n",
            "nt_epoch =    320  elapsed = 00:23  loss = 3.0462e+01  error = 6.3955e-02  \n",
            "nt_epoch =    330  elapsed = 00:24  loss = 2.8726e+01  error = 6.2990e-02  \n",
            "nt_epoch =    340  elapsed = 00:25  loss = 2.7016e+01  error = 5.9840e-02  \n",
            "nt_epoch =    350  elapsed = 00:25  loss = 2.5361e+01  error = 5.7496e-02  \n",
            "nt_epoch =    360  elapsed = 00:26  loss = 2.3662e+01  error = 5.3584e-02  \n",
            "nt_epoch =    370  elapsed = 00:26  loss = 2.2046e+01  error = 5.2511e-02  \n",
            "nt_epoch =    380  elapsed = 00:27  loss = 2.1022e+01  error = 5.0063e-02  \n",
            "nt_epoch =    390  elapsed = 00:27  loss = 1.9928e+01  error = 4.6555e-02  \n",
            "nt_epoch =    400  elapsed = 00:28  loss = 1.9081e+01  error = 4.6074e-02  \n",
            "nt_epoch =    410  elapsed = 00:29  loss = 1.8237e+01  error = 4.4871e-02  \n",
            "nt_epoch =    420  elapsed = 00:29  loss = 1.7489e+01  error = 4.4424e-02  \n",
            "nt_epoch =    430  elapsed = 00:30  loss = 1.6661e+01  error = 4.3817e-02  \n",
            "nt_epoch =    440  elapsed = 00:30  loss = 1.5855e+01  error = 4.0671e-02  \n",
            "nt_epoch =    450  elapsed = 00:31  loss = 1.5310e+01  error = 3.9715e-02  \n",
            "nt_epoch =    460  elapsed = 00:32  loss = 1.4456e+01  error = 4.0442e-02  \n",
            "nt_epoch =    470  elapsed = 00:32  loss = 1.3976e+01  error = 3.8537e-02  \n",
            "nt_epoch =    480  elapsed = 00:33  loss = 1.3140e+01  error = 3.4680e-02  \n",
            "nt_epoch =    490  elapsed = 00:33  loss = 1.2318e+01  error = 3.1593e-02  \n",
            "nt_epoch =    500  elapsed = 00:34  loss = 1.1914e+01  error = 3.0566e-02  \n",
            "nt_epoch =    510  elapsed = 00:34  loss = 1.1415e+01  error = 2.9723e-02  \n",
            "nt_epoch =    520  elapsed = 00:35  loss = 1.0964e+01  error = 2.8795e-02  \n",
            "nt_epoch =    530  elapsed = 00:36  loss = 1.0396e+01  error = 2.7549e-02  \n",
            "nt_epoch =    540  elapsed = 00:36  loss = 9.9143e+00  error = 2.7040e-02  \n",
            "nt_epoch =    550  elapsed = 00:37  loss = 9.4539e+00  error = 2.7334e-02  \n",
            "nt_epoch =    560  elapsed = 00:37  loss = 9.2210e+00  error = 2.7215e-02  \n",
            "nt_epoch =    570  elapsed = 00:38  loss = 8.8360e+00  error = 2.6945e-02  \n",
            "nt_epoch =    580  elapsed = 00:38  loss = 8.5266e+00  error = 2.7009e-02  \n",
            "nt_epoch =    590  elapsed = 00:39  loss = 8.1872e+00  error = 2.7105e-02  \n",
            "nt_epoch =    600  elapsed = 00:40  loss = 7.9418e+00  error = 2.6571e-02  \n",
            "nt_epoch =    610  elapsed = 00:40  loss = 7.7180e+00  error = 2.6100e-02  \n",
            "nt_epoch =    620  elapsed = 00:41  loss = 7.4581e+00  error = 2.5957e-02  \n",
            "nt_epoch =    630  elapsed = 00:41  loss = 7.2681e+00  error = 2.5734e-02  \n",
            "nt_epoch =    640  elapsed = 00:42  loss = 7.1173e+00  error = 2.5609e-02  \n",
            "nt_epoch =    650  elapsed = 00:42  loss = 6.9453e+00  error = 2.5529e-02  \n",
            "nt_epoch =    660  elapsed = 00:43  loss = 6.7457e+00  error = 2.5229e-02  \n",
            "nt_epoch =    670  elapsed = 00:44  loss = 6.6307e+00  error = 2.4988e-02  \n",
            "nt_epoch =    680  elapsed = 00:44  loss = 6.4753e+00  error = 2.5343e-02  \n",
            "nt_epoch =    690  elapsed = 00:45  loss = 6.3231e+00  error = 2.5790e-02  \n",
            "nt_epoch =    700  elapsed = 00:45  loss = 6.1639e+00  error = 2.5695e-02  \n",
            "nt_epoch =    710  elapsed = 00:46  loss = 5.9961e+00  error = 2.6015e-02  \n",
            "nt_epoch =    720  elapsed = 00:46  loss = 5.8354e+00  error = 2.6341e-02  \n",
            "nt_epoch =    730  elapsed = 00:47  loss = 5.7105e+00  error = 2.5917e-02  \n",
            "nt_epoch =    740  elapsed = 00:48  loss = 5.5833e+00  error = 2.5167e-02  \n",
            "nt_epoch =    750  elapsed = 00:48  loss = 5.4943e+00  error = 2.5266e-02  \n",
            "nt_epoch =    760  elapsed = 00:49  loss = 5.3760e+00  error = 2.5323e-02  \n",
            "nt_epoch =    770  elapsed = 00:49  loss = 5.2601e+00  error = 2.4862e-02  \n",
            "nt_epoch =    780  elapsed = 00:50  loss = 5.1686e+00  error = 2.3939e-02  \n",
            "nt_epoch =    790  elapsed = 00:50  loss = 5.0932e+00  error = 2.3714e-02  \n",
            "nt_epoch =    800  elapsed = 00:51  loss = 4.9893e+00  error = 2.3764e-02  \n",
            "nt_epoch =    810  elapsed = 00:52  loss = 4.8542e+00  error = 2.3656e-02  \n",
            "nt_epoch =    820  elapsed = 00:52  loss = 4.7767e+00  error = 2.4454e-02  \n",
            "nt_epoch =    830  elapsed = 00:53  loss = 4.6960e+00  error = 2.4885e-02  \n",
            "nt_epoch =    840  elapsed = 00:53  loss = 4.6348e+00  error = 2.4440e-02  \n",
            "nt_epoch =    850  elapsed = 00:54  loss = 4.5802e+00  error = 2.4621e-02  \n",
            "nt_epoch =    860  elapsed = 00:54  loss = 4.5139e+00  error = 2.4342e-02  \n",
            "nt_epoch =    870  elapsed = 00:55  loss = 4.4593e+00  error = 2.4073e-02  \n",
            "nt_epoch =    880  elapsed = 00:56  loss = 4.3838e+00  error = 2.4026e-02  \n",
            "nt_epoch =    890  elapsed = 00:56  loss = 4.3063e+00  error = 2.4245e-02  \n",
            "nt_epoch =    900  elapsed = 00:57  loss = 4.2378e+00  error = 2.3526e-02  \n",
            "nt_epoch =    910  elapsed = 00:57  loss = 4.1949e+00  error = 2.3150e-02  \n",
            "nt_epoch =    920  elapsed = 00:58  loss = 4.1115e+00  error = 2.3936e-02  \n",
            "nt_epoch =    930  elapsed = 00:58  loss = 4.0355e+00  error = 2.3859e-02  \n",
            "nt_epoch =    940  elapsed = 00:59  loss = 3.9595e+00  error = 2.3383e-02  \n",
            "nt_epoch =    950  elapsed = 01:00  loss = 3.8809e+00  error = 2.3325e-02  \n",
            "nt_epoch =    960  elapsed = 01:00  loss = 3.8198e+00  error = 2.3099e-02  \n",
            "nt_epoch =    970  elapsed = 01:01  loss = 3.7240e+00  error = 2.3252e-02  \n",
            "nt_epoch =    980  elapsed = 01:01  loss = 3.6540e+00  error = 2.2697e-02  \n",
            "nt_epoch =    990  elapsed = 01:02  loss = 3.5884e+00  error = 2.2541e-02  \n",
            "==================\n",
            "Training finished (epoch 200): duration = 01:03  error = 2.2291e-02  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9aFDcGpxAq2",
        "lines_to_next_cell": 0,
        "outputId": "1fdc7422-37bd-4b0b-9973-66725b11916d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "plot_inf_disc_results(x_star, idx_t_0, idx_t_1, x_0, u_0, ub, lb, u_1_pred, Exact_u, x, t)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 388.543x288.159 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoN7tCmSGDeO"
      },
      "source": [
        "# 3. Continuous Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkpuORIsGDeQ"
      },
      "source": [
        "$$u_t + \\lambda_1 u u_x - \\lambda_2 u_{xx} = 0$$\n",
        "\n",
        "With $\\lambda_1$ and $\\lambda_2$ real parameters of the differential operator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpUoecjeGDeR"
      },
      "source": [
        "Approximating $u(t,x)$ with a deep NN, we define the PINN:\n",
        "$$f := u_t + \\lambda_1 u u_x - \\lambda_2 u_{xx}.$$\n",
        "\n",
        "We train the shared parameters between the deep NN and the PINN minimizing the loss:\n",
        "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_u}|f(t_u^i,x_u^i)|^2,$$\n",
        "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ respectively the trainring data on $u(t,x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOPzdkKsJzA4"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKRYhyXqGDeT",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Data size on the solution u\n",
        "N_u = 2000\n",
        "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
        "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "tf_epochs = 100\n",
        "tf_optimizer = tf.keras.optimizers.Adam(\n",
        "  learning_rate=0.001)\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "nt_epochs = 1000\n",
        "nt_config = Struct()\n",
        "nt_config.learningRate = 0.8\n",
        "nt_config.maxIter = nt_epochs\n",
        "nt_config.nCorrection = 50\n",
        "nt_config.tolFun = 1.0 * np.finfo(float).eps\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTxvp1nJGDeb"
      },
      "source": [
        "## PINN class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9grEA3wGDed"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLOwP1UfGDee",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "class PhysicsInformedNN(object):\n",
        "  def __init__(self, layers, optimizer, logger, ub, lb):\n",
        "    # Descriptive Keras model [2, 20, …, 20, 1]\n",
        "    self.u_model = tf.keras.Sequential()\n",
        "    self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    self.u_model.add(tf.keras.layers.Lambda(\n",
        "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:]:\n",
        "        self.u_model.add(tf.keras.layers.Dense(\n",
        "          width, activation=tf.nn.tanh,\n",
        "          kernel_initializer='glorot_normal'))\n",
        "\n",
        "    # Computing the sizes of weights/biases for future decomposition\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    for i, width in enumerate(layers):\n",
        "      if i != 1:\n",
        "        self.sizes_w.append(int(width * layers[1]))\n",
        "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "    self.dtype = tf.float32\n",
        "\n",
        "    # Defining the two additional trainable variables for identification\n",
        "    self.lambda_1 = tf.Variable([0.0], dtype=self.dtype)\n",
        "    self.lambda_2 = tf.Variable([-6.0], dtype=self.dtype)\n",
        "    \n",
        "    self.optimizer = optimizer\n",
        "    self.logger = logger\n",
        "\n",
        "  # The actual PINN\n",
        "  def __f_model(self, X_u):\n",
        "    l1, l2 = self.get_params()\n",
        "    # Separating the collocation coordinates\n",
        "    x_f = tf.convert_to_tensor(X_u[:, 0:1], dtype=self.dtype)\n",
        "    t_f = tf.convert_to_tensor(X_u[:, 1:2], dtype=self.dtype)\n",
        "\n",
        "    # Using the new GradientTape paradigm of TF2.0,\n",
        "    # which keeps track of operations to get the gradient at runtime\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Watching the two inputs we’ll need later, x and t\n",
        "      tape.watch(x_f)\n",
        "      tape.watch(t_f)\n",
        "      # Packing together the inputs\n",
        "      X_f = tf.stack([x_f[:,0], t_f[:,0]], axis=1)\n",
        "\n",
        "\n",
        "      # Getting the prediction\n",
        "      u = self.u_model(X_f)\n",
        "      # Deriving INSIDE the tape (since we’ll need the x derivative of this later, u_xx)\n",
        "      u_x = tape.gradient(u, x_f)\n",
        "    \n",
        "    # Getting the other derivatives\n",
        "    u_xx = tape.gradient(u_x, x_f)\n",
        "    u_t = tape.gradient(u, t_f)\n",
        "\n",
        "    # Letting the tape go\n",
        "    del tape\n",
        "\n",
        "    # Buidling the PINNs\n",
        "    return u_t + l1*u*u_x - l2*u_xx\n",
        "\n",
        "  # Defining custom loss\n",
        "  def __loss(self, X_u, u, u_pred):\n",
        "    f_pred = self.__f_model(X_u)\n",
        "    return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
        "      tf.reduce_mean(tf.square(f_pred))\n",
        "\n",
        "  def __grad(self, X, u):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.__loss(X, u, self.u_model(X))\n",
        "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "\n",
        "  def __wrap_training_variables(self):\n",
        "    var = self.u_model.trainable_variables\n",
        "    var.extend([self.lambda_1, self.lambda_2])\n",
        "    return var\n",
        "\n",
        "  def get_weights(self):\n",
        "      w = []\n",
        "      for layer in self.u_model.layers[1:]:\n",
        "        weights_biases = layer.get_weights()\n",
        "        weights = weights_biases[0].flatten()\n",
        "        biases = weights_biases[1]\n",
        "        w.extend(weights)\n",
        "        w.extend(biases)\n",
        "      w.extend(self.lambda_1.numpy())\n",
        "      w.extend(self.lambda_2.numpy())\n",
        "      return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.u_model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "    self.lambda_1.assign([w[-2]])\n",
        "    self.lambda_2.assign([w[-1]])\n",
        "\n",
        "  def get_params(self, numpy=False):\n",
        "    l1 = self.lambda_1\n",
        "    l2 = tf.exp(self.lambda_2)\n",
        "    if numpy:\n",
        "      return l1.numpy()[0], l2.numpy()[0]\n",
        "    return l1, l2\n",
        "\n",
        "  def summary(self):\n",
        "    return self.u_model.summary()\n",
        "\n",
        "  # The training function\n",
        "  def fit(self, X_u, u, tf_epochs, nt_config):\n",
        "    self.logger.log_train_start(self)\n",
        "\n",
        "    # Creating the tensors\n",
        "    X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
        "    u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
        "\n",
        "    def log_train_epoch(epoch, loss, is_iter):\n",
        "      l1, l2 = self.get_params(numpy=True)\n",
        "      custom = f\"l1 = {l1:5f}  l2 = {l2:8f}\"\n",
        "      self.logger.log_train_epoch(epoch, loss, custom, is_iter)\n",
        "\n",
        "    self.logger.log_train_opt(\"Adam\")\n",
        "    for epoch in range(tf_epochs):\n",
        "      # Optimization step\n",
        "      loss_value, grads = self.__grad(X_u, u)\n",
        "      self.optimizer.apply_gradients(\n",
        "        zip(grads, self.__wrap_training_variables()))\n",
        "      log_train_epoch(epoch, loss_value, False)\n",
        "\n",
        "    self.logger.log_train_opt(\"LBFGS\")\n",
        "    def loss_and_flat_grad(w):\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        tape.watch(self.lambda_1)\n",
        "        tape.watch(self.lambda_2)\n",
        "        loss_value = self.__loss(X_u, u, self.u_model(X_u))\n",
        "      grad = tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "      grad_flat = []\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat =  tf.concat(grad_flat, 0)\n",
        "      return loss_value, grad_flat\n",
        "    # tfp.optimizer.lbfgs_minimize(\n",
        "    #   loss_and_flat_grad,\n",
        "    #   initial_position=self.get_weights(),\n",
        "    #   num_correction_pairs=nt_config.nCorrection,\n",
        "    #   max_iterations=nt_config.maxIter,\n",
        "    #   f_relative_tolerance=nt_config.tolFun,\n",
        "    #   tolerance=nt_config.tolFun,\n",
        "    #   parallel_iterations=6)\n",
        "    lbfgs(loss_and_flat_grad,\n",
        "      self.get_weights(),\n",
        "      nt_config, Struct(), True, log_train_epoch)\n",
        "    \n",
        "    l1, l2 = self.get_params(numpy=True)\n",
        "    self.logger.log_train_end(tf_epochs, f\"l1 = {l1:5f}  l2 = {l2:8f}\")\n",
        "\n",
        "  def predict(self, X_star):\n",
        "    u_star = self.u_model(X_star)\n",
        "    f_star = self.__f_model(X_star)\n",
        "    return u_star.numpy(), f_star.numpy()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rWEI708GDei"
      },
      "source": [
        "## Training and plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxkeBW46GDek",
        "lines_to_next_cell": 2,
        "outputId": "b9abc3d5-d46a-43ee-e83f-0c3156da8a90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Getting the data\n",
        "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "  X_u_train, u_train, ub, lb = prep_data(path, N_u, noise=0.0)\n",
        "lambdas_star = (1.0, 0.01/np.pi)\n",
        "\n",
        "# Creating the model and training\n",
        "logger = Logger(frequency=10)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, ub, lb)\n",
        "def error():\n",
        "  l1, l2 = pinn.get_params(numpy=True)\n",
        "  l1_star, l2_star = lambdas_star\n",
        "  error_lambda_1 = np.abs(l1 - l1_star) / l1_star\n",
        "  error_lambda_2 = np.abs(l2 - l2_star) / l2_star\n",
        "  return (error_lambda_1 + error_lambda_2) / 2\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_pred, f_pred = pinn.predict(X_star)\n",
        "lambda_1_pred, lambda_2_pred = pinn.get_params(numpy=True)\n",
        "\n",
        "# Noise case\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "  X_u_train, u_train, ub, lb = prep_data(path, N_u, noise=0.01)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, ub, lb)\n",
        "pinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
        "lambda_1_pred_noise, lambda_2_pred_noise = pinn.get_params(numpy=True)\n",
        "\n",
        "print(\"l1: \", lambda_1_pred)\n",
        "print(\"l2: \", lambda_2_pred)\n",
        "print(\"l1_noise: \", lambda_1_pred_noise)\n",
        "print(\"l2_noise: \", lambda_2_pred_noise)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n",
            "Eager execution: True\n",
            "GPU-accerelated: True\n",
            "\n",
            "Training started\n",
            "================\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_4 (Lambda)            (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 20)                60        \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 3,021\n",
            "Trainable params: 3,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "—— Starting Adam optimization ——\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "tf_epoch =      0  elapsed = 00:00  loss = 5.0462e-01  error = 6.1009e-01  l1 = 0.000966  l2 = 0.002479\n",
            "tf_epoch =     10  elapsed = 00:00  loss = 3.0904e-01  error = 6.0824e-01  l1 = 0.003006  l2 = 0.002484\n",
            "tf_epoch =     20  elapsed = 00:01  loss = 2.5373e-01  error = 6.0873e-01  l1 = -0.005562  l2 = 0.002509\n",
            "tf_epoch =     30  elapsed = 00:01  loss = 2.1768e-01  error = 6.0977e-01  l1 = -0.017259  l2 = 0.002539\n",
            "tf_epoch =     40  elapsed = 00:01  loss = 2.0051e-01  error = 6.1082e-01  l1 = -0.029674  l2 = 0.002572\n",
            "tf_epoch =     50  elapsed = 00:02  loss = 1.8089e-01  error = 6.1126e-01  l1 = -0.040556  l2 = 0.002604\n",
            "tf_epoch =     60  elapsed = 00:02  loss = 1.6080e-01  error = 6.1117e-01  l1 = -0.047921  l2 = 0.002628\n",
            "tf_epoch =     70  elapsed = 00:03  loss = 1.4041e-01  error = 6.1319e-01  l1 = -0.048966  l2 = 0.002618\n",
            "tf_epoch =     80  elapsed = 00:03  loss = 1.2115e-01  error = 6.1601e-01  l1 = -0.041011  l2 = 0.002575\n",
            "tf_epoch =     90  elapsed = 00:04  loss = 1.0501e-01  error = 6.1625e-01  l1 = -0.025119  l2 = 0.002523\n",
            "—— Starting LBFGS optimization ——\n",
            "nt_epoch =     10  elapsed = 00:05  loss = 5.3961e-02  error = 5.4903e-01  l1 = 0.133418  l2 = 0.002446\n",
            "nt_epoch =     20  elapsed = 00:05  loss = 3.4094e-02  error = 5.4347e-01  l1 = 0.158512  l2 = 0.002402\n",
            "nt_epoch =     30  elapsed = 00:06  loss = 2.7656e-02  error = 5.6129e-01  l1 = 0.134474  l2 = 0.002365\n",
            "nt_epoch =     40  elapsed = 00:07  loss = 2.4796e-02  error = 5.3338e-01  l1 = 0.184706  l2 = 0.002383\n",
            "nt_epoch =     50  elapsed = 00:07  loss = 2.1527e-02  error = 4.9776e-01  l1 = 0.238602  l2 = 0.002438\n",
            "nt_epoch =     60  elapsed = 00:08  loss = 1.9047e-02  error = 4.5239e-01  l1 = 0.308804  l2 = 0.002503\n",
            "nt_epoch =     70  elapsed = 00:09  loss = 1.6970e-02  error = 3.8989e-01  l1 = 0.411400  l2 = 0.002575\n",
            "nt_epoch =     80  elapsed = 00:10  loss = 1.5937e-02  error = 3.9152e-01  l1 = 0.403223  l2 = 0.002590\n",
            "nt_epoch =     90  elapsed = 00:10  loss = 1.4742e-02  error = 3.7853e-01  l1 = 0.429072  l2 = 0.002591\n",
            "nt_epoch =    100  elapsed = 00:11  loss = 1.3909e-02  error = 3.7558e-01  l1 = 0.436719  l2 = 0.002585\n",
            "nt_epoch =    110  elapsed = 00:12  loss = 1.2548e-02  error = 3.4407e-01  l1 = 0.480565  l2 = 0.002646\n",
            "nt_epoch =    120  elapsed = 00:13  loss = 1.1157e-02  error = 3.1935e-01  l1 = 0.499539  l2 = 0.002743\n",
            "nt_epoch =    130  elapsed = 00:13  loss = 1.0212e-02  error = 3.0308e-01  l1 = 0.502462  l2 = 0.002837\n",
            "nt_epoch =    140  elapsed = 00:14  loss = 8.9785e-03  error = 2.6087e-01  l1 = 0.535568  l2 = 0.003001\n",
            "nt_epoch =    150  elapsed = 00:15  loss = 8.3251e-03  error = 2.1885e-01  l1 = 0.573406  l2 = 0.003148\n",
            "nt_epoch =    160  elapsed = 00:16  loss = 7.3332e-03  error = 2.1152e-01  l1 = 0.618268  l2 = 0.003315\n",
            "nt_epoch =    170  elapsed = 00:16  loss = 6.5442e-03  error = 2.2191e-01  l1 = 0.642121  l2 = 0.003457\n",
            "nt_epoch =    180  elapsed = 00:17  loss = 5.4155e-03  error = 2.0725e-01  l1 = 0.691367  l2 = 0.003520\n",
            "nt_epoch =    190  elapsed = 00:18  loss = 4.9941e-03  error = 2.1078e-01  l1 = 0.697291  l2 = 0.003561\n",
            "nt_epoch =    200  elapsed = 00:19  loss = 4.1184e-03  error = 1.9453e-01  l1 = 0.758941  l2 = 0.003654\n",
            "nt_epoch =    210  elapsed = 00:19  loss = 3.5118e-03  error = 1.8510e-01  l1 = 0.800586  l2 = 0.003727\n",
            "nt_epoch =    220  elapsed = 00:20  loss = 3.1183e-03  error = 1.9098e-01  l1 = 0.805711  l2 = 0.003780\n",
            "nt_epoch =    230  elapsed = 00:21  loss = 2.8242e-03  error = 1.8764e-01  l1 = 0.843793  l2 = 0.003880\n",
            "nt_epoch =    240  elapsed = 00:22  loss = 2.5334e-03  error = 1.8734e-01  l1 = 0.863828  l2 = 0.003942\n",
            "nt_epoch =    250  elapsed = 00:22  loss = 2.2394e-03  error = 1.8902e-01  l1 = 0.869431  l2 = 0.003971\n",
            "nt_epoch =    260  elapsed = 00:23  loss = 2.0127e-03  error = 1.8618e-01  l1 = 0.890146  l2 = 0.004019\n",
            "nt_epoch =    270  elapsed = 00:24  loss = 1.8302e-03  error = 1.8316e-01  l1 = 0.902198  l2 = 0.004038\n",
            "nt_epoch =    280  elapsed = 00:25  loss = 1.6966e-03  error = 1.7694e-01  l1 = 0.913932  l2 = 0.004036\n",
            "nt_epoch =    290  elapsed = 00:25  loss = 1.5421e-03  error = 1.6540e-01  l1 = 0.927193  l2 = 0.004004\n",
            "nt_epoch =    300  elapsed = 00:26  loss = 1.3535e-03  error = 1.5354e-01  l1 = 0.935592  l2 = 0.003956\n",
            "nt_epoch =    310  elapsed = 00:27  loss = 1.2137e-03  error = 1.4246e-01  l1 = 0.958585  l2 = 0.003958\n",
            "nt_epoch =    320  elapsed = 00:28  loss = 1.0933e-03  error = 1.3862e-01  l1 = 0.957845  l2 = 0.003931\n",
            "nt_epoch =    330  elapsed = 00:28  loss = 1.0297e-03  error = 1.3571e-01  l1 = 0.954758  l2 = 0.003903\n",
            "nt_epoch =    340  elapsed = 00:29  loss = 9.8551e-04  error = 1.2842e-01  l1 = 0.957822  l2 = 0.003866\n",
            "nt_epoch =    350  elapsed = 00:30  loss = 9.0732e-04  error = 1.1974e-01  l1 = 0.959062  l2 = 0.003815\n",
            "nt_epoch =    360  elapsed = 00:31  loss = 8.7263e-04  error = 1.1177e-01  l1 = 0.965393  l2 = 0.003784\n",
            "nt_epoch =    370  elapsed = 00:31  loss = 8.1820e-04  error = 1.0616e-01  l1 = 0.963533  l2 = 0.003743\n",
            "nt_epoch =    380  elapsed = 00:32  loss = 7.9311e-04  error = 1.0531e-01  l1 = 0.961519  l2 = 0.003731\n",
            "nt_epoch =    390  elapsed = 00:33  loss = 7.6110e-04  error = 9.9180e-02  l1 = 0.963985  l2 = 0.003700\n",
            "nt_epoch =    400  elapsed = 00:34  loss = 7.3346e-04  error = 9.5253e-02  l1 = 0.966682  l2 = 0.003683\n",
            "nt_epoch =    410  elapsed = 00:34  loss = 7.1182e-04  error = 9.2311e-02  l1 = 0.964764  l2 = 0.003659\n",
            "nt_epoch =    420  elapsed = 00:35  loss = 6.7978e-04  error = 9.1614e-02  l1 = 0.960418  l2 = 0.003640\n",
            "nt_epoch =    430  elapsed = 00:36  loss = 6.5083e-04  error = 8.4163e-02  l1 = 0.966288  l2 = 0.003612\n",
            "nt_epoch =    440  elapsed = 00:37  loss = 6.3625e-04  error = 8.2243e-02  l1 = 0.965459  l2 = 0.003597\n",
            "nt_epoch =    450  elapsed = 00:37  loss = 6.1511e-04  error = 7.8914e-02  l1 = 0.967141  l2 = 0.003581\n",
            "nt_epoch =    460  elapsed = 00:38  loss = 5.9978e-04  error = 7.5806e-02  l1 = 0.970169  l2 = 0.003571\n",
            "nt_epoch =    470  elapsed = 00:39  loss = 5.8780e-04  error = 7.5744e-02  l1 = 0.965533  l2 = 0.003556\n",
            "nt_epoch =    480  elapsed = 00:40  loss = 5.7194e-04  error = 7.6427e-02  l1 = 0.961729  l2 = 0.003548\n",
            "nt_epoch =    490  elapsed = 00:40  loss = 5.5888e-04  error = 7.3703e-02  l1 = 0.959836  l2 = 0.003524\n",
            "nt_epoch =    500  elapsed = 00:41  loss = 5.3934e-04  error = 6.9283e-02  l1 = 0.958414  l2 = 0.003492\n",
            "nt_epoch =    510  elapsed = 00:42  loss = 5.2205e-04  error = 6.1106e-02  l1 = 0.963402  l2 = 0.003456\n",
            "nt_epoch =    520  elapsed = 00:43  loss = 5.0717e-04  error = 6.0300e-02  l1 = 0.964964  l2 = 0.003455\n",
            "nt_epoch =    530  elapsed = 00:43  loss = 4.8960e-04  error = 5.9808e-02  l1 = 0.968141  l2 = 0.003462\n",
            "nt_epoch =    540  elapsed = 00:44  loss = 4.7966e-04  error = 5.6726e-02  l1 = 0.971576  l2 = 0.003454\n",
            "nt_epoch =    550  elapsed = 00:45  loss = 4.6981e-04  error = 5.5311e-02  l1 = 0.972069  l2 = 0.003446\n",
            "nt_epoch =    560  elapsed = 00:46  loss = 4.5421e-04  error = 5.1943e-02  l1 = 0.972617  l2 = 0.003427\n",
            "nt_epoch =    570  elapsed = 00:46  loss = 4.4348e-04  error = 4.7107e-02  l1 = 0.973771  l2 = 0.003399\n",
            "nt_epoch =    580  elapsed = 00:47  loss = 4.3538e-04  error = 4.6141e-02  l1 = 0.973293  l2 = 0.003392\n",
            "nt_epoch =    590  elapsed = 00:48  loss = 4.3129e-04  error = 4.5339e-02  l1 = 0.974091  l2 = 0.003389\n",
            "nt_epoch =    600  elapsed = 00:49  loss = 4.2164e-04  error = 4.7553e-02  l1 = 0.971848  l2 = 0.003396\n",
            "nt_epoch =    610  elapsed = 00:49  loss = 4.1288e-04  error = 4.6967e-02  l1 = 0.972193  l2 = 0.003394\n",
            "nt_epoch =    620  elapsed = 00:50  loss = 4.0463e-04  error = 4.5577e-02  l1 = 0.973297  l2 = 0.003388\n",
            "nt_epoch =    630  elapsed = 00:51  loss = 3.9456e-04  error = 4.4386e-02  l1 = 0.976329  l2 = 0.003390\n",
            "nt_epoch =    640  elapsed = 00:52  loss = 3.8584e-04  error = 4.5237e-02  l1 = 0.976264  l2 = 0.003396\n",
            "nt_epoch =    650  elapsed = 00:52  loss = 3.8158e-04  error = 4.4487e-02  l1 = 0.976640  l2 = 0.003392\n",
            "nt_epoch =    660  elapsed = 00:53  loss = 3.7513e-04  error = 4.4174e-02  l1 = 0.977501  l2 = 0.003393\n",
            "nt_epoch =    670  elapsed = 00:54  loss = 3.6670e-04  error = 4.1704e-02  l1 = 0.977797  l2 = 0.003378\n",
            "nt_epoch =    680  elapsed = 00:55  loss = 3.5808e-04  error = 3.9598e-02  l1 = 0.979469  l2 = 0.003370\n",
            "nt_epoch =    690  elapsed = 00:56  loss = 3.4772e-04  error = 3.3865e-02  l1 = 0.981392  l2 = 0.003339\n",
            "nt_epoch =    700  elapsed = 00:56  loss = 3.3328e-04  error = 3.1894e-02  l1 = 0.982317  l2 = 0.003330\n",
            "nt_epoch =    710  elapsed = 00:57  loss = 3.1883e-04  error = 3.2167e-02  l1 = 0.982093  l2 = 0.003331\n",
            "nt_epoch =    720  elapsed = 00:58  loss = 3.1112e-04  error = 3.2253e-02  l1 = 0.982462  l2 = 0.003333\n",
            "nt_epoch =    730  elapsed = 00:59  loss = 3.0698e-04  error = 3.2057e-02  l1 = 0.983375  l2 = 0.003334\n",
            "nt_epoch =    740  elapsed = 00:59  loss = 3.0226e-04  error = 3.1072e-02  l1 = 0.983680  l2 = 0.003329\n",
            "nt_epoch =    750  elapsed = 01:00  loss = 2.9820e-04  error = 2.8766e-02  l1 = 0.983795  l2 = 0.003315\n",
            "nt_epoch =    760  elapsed = 01:01  loss = 2.9431e-04  error = 2.8956e-02  l1 = 0.983468  l2 = 0.003315\n",
            "nt_epoch =    770  elapsed = 01:02  loss = 2.8985e-04  error = 3.0259e-02  l1 = 0.983018  l2 = 0.003322\n",
            "nt_epoch =    780  elapsed = 01:02  loss = 2.8509e-04  error = 3.0800e-02  l1 = 0.982656  l2 = 0.003324\n",
            "nt_epoch =    790  elapsed = 01:03  loss = 2.8069e-04  error = 3.1649e-02  l1 = 0.982114  l2 = 0.003328\n",
            "nt_epoch =    800  elapsed = 01:04  loss = 2.7677e-04  error = 3.2012e-02  l1 = 0.982414  l2 = 0.003331\n",
            "nt_epoch =    810  elapsed = 01:05  loss = 2.7538e-04  error = 3.1938e-02  l1 = 0.982535  l2 = 0.003331\n",
            "nt_epoch =    820  elapsed = 01:05  loss = 2.7228e-04  error = 3.1826e-02  l1 = 0.981913  l2 = 0.003328\n",
            "nt_epoch =    830  elapsed = 01:06  loss = 2.6862e-04  error = 3.2500e-02  l1 = 0.981333  l2 = 0.003331\n",
            "nt_epoch =    840  elapsed = 01:07  loss = 2.6290e-04  error = 3.2552e-02  l1 = 0.981337  l2 = 0.003331\n",
            "nt_epoch =    850  elapsed = 01:08  loss = 2.5633e-04  error = 3.2131e-02  l1 = 0.980540  l2 = 0.003326\n",
            "nt_epoch =    860  elapsed = 01:09  loss = 2.5291e-04  error = 3.2388e-02  l1 = 0.979990  l2 = 0.003326\n",
            "nt_epoch =    870  elapsed = 01:09  loss = 2.5007e-04  error = 3.2656e-02  l1 = 0.979817  l2 = 0.003327\n",
            "nt_epoch =    880  elapsed = 01:10  loss = 2.4654e-04  error = 3.2678e-02  l1 = 0.980141  l2 = 0.003328\n",
            "nt_epoch =    890  elapsed = 01:11  loss = 2.4265e-04  error = 3.1656e-02  l1 = 0.980979  l2 = 0.003324\n",
            "nt_epoch =    900  elapsed = 01:12  loss = 2.3958e-04  error = 3.1306e-02  l1 = 0.980983  l2 = 0.003322\n",
            "nt_epoch =    910  elapsed = 01:12  loss = 2.3760e-04  error = 3.1994e-02  l1 = 0.980504  l2 = 0.003325\n",
            "nt_epoch =    920  elapsed = 01:13  loss = 2.3477e-04  error = 3.1807e-02  l1 = 0.980752  l2 = 0.003324\n",
            "nt_epoch =    930  elapsed = 01:14  loss = 2.2992e-04  error = 3.1437e-02  l1 = 0.980694  l2 = 0.003322\n",
            "nt_epoch =    940  elapsed = 01:15  loss = 2.2738e-04  error = 3.1049e-02  l1 = 0.980741  l2 = 0.003319\n",
            "nt_epoch =    950  elapsed = 01:16  loss = 2.2502e-04  error = 3.1599e-02  l1 = 0.980280  l2 = 0.003321\n",
            "nt_epoch =    960  elapsed = 01:16  loss = 2.2254e-04  error = 3.1434e-02  l1 = 0.980299  l2 = 0.003321\n",
            "nt_epoch =    970  elapsed = 01:17  loss = 2.1844e-04  error = 3.1362e-02  l1 = 0.980314  l2 = 0.003320\n",
            "nt_epoch =    980  elapsed = 01:18  loss = 2.1315e-04  error = 2.9478e-02  l1 = 0.981533  l2 = 0.003312\n",
            "nt_epoch =    990  elapsed = 01:19  loss = 2.0997e-04  error = 2.8116e-02  l1 = 0.982391  l2 = 0.003306\n",
            "==================\n",
            "Training finished (epoch 100): duration = 01:19  error = 2.7045e-02  l1 = 0.983534  l2 = 0.003303\n",
            "\n",
            "Training started\n",
            "================\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_5 (Lambda)            (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 20)                60        \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 3,021\n",
            "Trainable params: 3,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "—— Starting Adam optimization ——\n",
            "tf_epoch =      0  elapsed = 01:20  loss = 7.1296e-01  error = 6.1122e-01  l1 = -0.000719  l2 = 0.002477\n",
            "tf_epoch =     10  elapsed = 01:20  loss = 3.5663e-01  error = 6.1221e-01  l1 = -0.002358  l2 = 0.002476\n",
            "tf_epoch =     20  elapsed = 01:20  loss = 3.0855e-01  error = 6.1490e-01  l1 = -0.012823  l2 = 0.002492\n",
            "tf_epoch =     30  elapsed = 01:21  loss = 2.3833e-01  error = 6.1410e-01  l1 = -0.026476  l2 = 0.002541\n",
            "tf_epoch =     40  elapsed = 01:21  loss = 2.0588e-01  error = 6.1324e-01  l1 = -0.043189  l2 = 0.002600\n",
            "tf_epoch =     50  elapsed = 01:22  loss = 1.7849e-01  error = 6.1274e-01  l1 = -0.055440  l2 = 0.002642\n",
            "tf_epoch =     60  elapsed = 01:22  loss = 1.5024e-01  error = 6.1714e-01  l1 = -0.060064  l2 = 0.002629\n",
            "tf_epoch =     70  elapsed = 01:23  loss = 1.2556e-01  error = 6.2369e-01  l1 = -0.054402  l2 = 0.002569\n",
            "tf_epoch =     80  elapsed = 01:23  loss = 1.0683e-01  error = 6.2366e-01  l1 = -0.031754  l2 = 0.002497\n",
            "tf_epoch =     90  elapsed = 01:23  loss = 9.3001e-02  error = 6.2094e-01  l1 = -0.003407  l2 = 0.002424\n",
            "—— Starting LBFGS optimization ——\n",
            "nt_epoch =     10  elapsed = 01:24  loss = 4.7980e-02  error = 5.6873e-01  l1 = 0.125832  l2 = 0.002345\n",
            "nt_epoch =     20  elapsed = 01:25  loss = 3.3660e-02  error = 5.5736e-01  l1 = 0.149743  l2 = 0.002341\n",
            "nt_epoch =     30  elapsed = 01:26  loss = 2.9291e-02  error = 5.7310e-01  l1 = 0.127310  l2 = 0.002312\n",
            "nt_epoch =     40  elapsed = 01:26  loss = 2.6548e-02  error = 5.6864e-01  l1 = 0.144660  l2 = 0.002286\n",
            "nt_epoch =     50  elapsed = 01:27  loss = 2.4826e-02  error = 5.3578e-01  l1 = 0.192934  l2 = 0.002341\n",
            "nt_epoch =     60  elapsed = 01:28  loss = 2.2356e-02  error = 4.7337e-01  l1 = 0.253614  l2 = 0.002545\n",
            "nt_epoch =     70  elapsed = 01:29  loss = 2.0369e-02  error = 4.3301e-01  l1 = 0.309729  l2 = 0.002624\n",
            "nt_epoch =     80  elapsed = 01:29  loss = 1.8352e-02  error = 3.9342e-01  l1 = 0.356272  l2 = 0.002728\n",
            "nt_epoch =     90  elapsed = 01:30  loss = 1.7027e-02  error = 3.8988e-01  l1 = 0.345783  l2 = 0.002784\n",
            "nt_epoch =    100  elapsed = 01:31  loss = 1.6423e-02  error = 3.6305e-01  l1 = 0.377847  l2 = 0.002852\n",
            "nt_epoch =    110  elapsed = 01:31  loss = 1.5665e-02  error = 3.2862e-01  l1 = 0.392720  l2 = 0.003024\n",
            "nt_epoch =    120  elapsed = 01:32  loss = 1.4838e-02  error = 2.9726e-01  l1 = 0.434165  l2 = 0.003274\n",
            "nt_epoch =    130  elapsed = 01:33  loss = 1.3688e-02  error = 3.1920e-01  l1 = 0.471081  l2 = 0.003532\n",
            "nt_epoch =    140  elapsed = 01:34  loss = 1.2546e-02  error = 3.2915e-01  l1 = 0.488165  l2 = 0.003649\n",
            "nt_epoch =    150  elapsed = 01:34  loss = 1.1538e-02  error = 3.4508e-01  l1 = 0.514592  l2 = 0.003835\n",
            "nt_epoch =    160  elapsed = 01:35  loss = 1.0469e-02  error = 3.4651e-01  l1 = 0.574255  l2 = 0.004034\n",
            "nt_epoch =    170  elapsed = 01:36  loss = 9.2037e-03  error = 3.4638e-01  l1 = 0.615209  l2 = 0.004163\n",
            "nt_epoch =    180  elapsed = 01:37  loss = 8.4019e-03  error = 3.5249e-01  l1 = 0.611472  l2 = 0.004190\n",
            "nt_epoch =    190  elapsed = 01:37  loss = 7.8408e-03  error = 3.4849e-01  l1 = 0.650167  l2 = 0.004288\n",
            "nt_epoch =    200  elapsed = 01:38  loss = 7.0951e-03  error = 3.6429e-01  l1 = 0.664915  l2 = 0.004436\n",
            "nt_epoch =    210  elapsed = 01:39  loss = 6.3987e-03  error = 3.7088e-01  l1 = 0.731612  l2 = 0.004690\n",
            "nt_epoch =    220  elapsed = 01:40  loss = 5.9399e-03  error = 3.9137e-01  l1 = 0.734495  l2 = 0.004829\n",
            "nt_epoch =    230  elapsed = 01:40  loss = 5.3804e-03  error = 3.9950e-01  l1 = 0.780382  l2 = 0.005027\n",
            "nt_epoch =    240  elapsed = 01:41  loss = 4.8209e-03  error = 4.0383e-01  l1 = 0.809926  l2 = 0.005149\n",
            "nt_epoch =    250  elapsed = 01:42  loss = 4.3911e-03  error = 4.1736e-01  l1 = 0.806712  l2 = 0.005225\n",
            "nt_epoch =    260  elapsed = 01:43  loss = 3.9738e-03  error = 4.0929e-01  l1 = 0.849889  l2 = 0.005311\n",
            "nt_epoch =    270  elapsed = 01:43  loss = 3.7212e-03  error = 4.1197e-01  l1 = 0.838289  l2 = 0.005291\n",
            "nt_epoch =    280  elapsed = 01:44  loss = 3.3371e-03  error = 3.9829e-01  l1 = 0.877373  l2 = 0.005328\n",
            "nt_epoch =    290  elapsed = 01:45  loss = 3.0242e-03  error = 3.8524e-01  l1 = 0.889934  l2 = 0.005285\n",
            "nt_epoch =    300  elapsed = 01:46  loss = 2.8423e-03  error = 3.8246e-01  l1 = 0.889197  l2 = 0.005265\n",
            "nt_epoch =    310  elapsed = 01:46  loss = 2.5035e-03  error = 3.6515e-01  l1 = 0.901560  l2 = 0.005194\n",
            "nt_epoch =    320  elapsed = 01:47  loss = 2.2825e-03  error = 3.5135e-01  l1 = 0.931500  l2 = 0.005202\n",
            "nt_epoch =    330  elapsed = 01:48  loss = 2.0957e-03  error = 3.3972e-01  l1 = 0.922765  l2 = 0.005100\n",
            "nt_epoch =    340  elapsed = 01:49  loss = 1.9538e-03  error = 3.3140e-01  l1 = 0.922318  l2 = 0.005046\n",
            "nt_epoch =    350  elapsed = 01:49  loss = 1.7695e-03  error = 3.1051e-01  l1 = 0.936975  l2 = 0.004959\n",
            "nt_epoch =    360  elapsed = 01:50  loss = 1.6347e-03  error = 2.9854e-01  l1 = 0.950849  l2 = 0.004927\n",
            "nt_epoch =    370  elapsed = 01:51  loss = 1.5382e-03  error = 2.9150e-01  l1 = 0.958013  l2 = 0.004905\n",
            "nt_epoch =    380  elapsed = 01:52  loss = 1.4119e-03  error = 2.7067e-01  l1 = 0.980467  l2 = 0.004844\n",
            "nt_epoch =    390  elapsed = 01:52  loss = 1.3082e-03  error = 2.5800e-01  l1 = 0.981996  l2 = 0.004768\n",
            "nt_epoch =    400  elapsed = 01:53  loss = 1.1835e-03  error = 2.5190e-01  l1 = 0.982852  l2 = 0.004732\n",
            "nt_epoch =    410  elapsed = 01:54  loss = 1.0388e-03  error = 2.3941e-01  l1 = 0.989380  l2 = 0.004673\n",
            "nt_epoch =    420  elapsed = 01:55  loss = 9.8755e-04  error = 2.3534e-01  l1 = 0.986706  l2 = 0.004639\n",
            "nt_epoch =    430  elapsed = 01:55  loss = 9.0948e-04  error = 2.2597e-01  l1 = 0.992747  l2 = 0.004599\n",
            "nt_epoch =    440  elapsed = 01:56  loss = 8.6239e-04  error = 2.2117e-01  l1 = 0.992900  l2 = 0.004568\n",
            "nt_epoch =    450  elapsed = 01:57  loss = 8.1095e-04  error = 2.1874e-01  l1 = 0.988456  l2 = 0.004539\n",
            "nt_epoch =    460  elapsed = 01:58  loss = 7.7736e-04  error = 2.1660e-01  l1 = 0.986109  l2 = 0.004518\n",
            "nt_epoch =    470  elapsed = 01:58  loss = 7.3936e-04  error = 2.1394e-01  l1 = 0.989386  l2 = 0.004511\n",
            "nt_epoch =    480  elapsed = 01:59  loss = 7.0020e-04  error = 2.1026e-01  l1 = 0.988179  l2 = 0.004484\n",
            "nt_epoch =    490  elapsed = 02:00  loss = 6.8590e-04  error = 2.0983e-01  l1 = 0.988062  l2 = 0.004481\n",
            "nt_epoch =    500  elapsed = 02:01  loss = 6.4806e-04  error = 2.0217e-01  l1 = 0.989565  l2 = 0.004437\n",
            "nt_epoch =    510  elapsed = 02:01  loss = 6.1925e-04  error = 1.8923e-01  l1 = 0.992066  l2 = 0.004363\n",
            "nt_epoch =    520  elapsed = 02:02  loss = 5.7940e-04  error = 1.8076e-01  l1 = 0.989608  l2 = 0.004301\n",
            "nt_epoch =    530  elapsed = 02:03  loss = 5.5905e-04  error = 1.7894e-01  l1 = 0.988796  l2 = 0.004287\n",
            "nt_epoch =    540  elapsed = 02:04  loss = 5.4625e-04  error = 1.7471e-01  l1 = 0.989643  l2 = 0.004262\n",
            "nt_epoch =    550  elapsed = 02:04  loss = 5.1982e-04  error = 1.7155e-01  l1 = 0.986517  l2 = 0.004232\n",
            "nt_epoch =    560  elapsed = 02:05  loss = 4.9995e-04  error = 1.6717e-01  l1 = 0.983798  l2 = 0.004196\n",
            "nt_epoch =    570  elapsed = 02:06  loss = 4.8165e-04  error = 1.5783e-01  l1 = 0.980590  l2 = 0.004126\n",
            "nt_epoch =    580  elapsed = 02:07  loss = 4.6916e-04  error = 1.5253e-01  l1 = 0.977149  l2 = 0.004081\n",
            "nt_epoch =    590  elapsed = 02:07  loss = 4.5630e-04  error = 1.4645e-01  l1 = 0.976750  l2 = 0.004041\n",
            "nt_epoch =    600  elapsed = 02:08  loss = 4.4567e-04  error = 1.4551e-01  l1 = 0.977207  l2 = 0.004037\n",
            "nt_epoch =    610  elapsed = 02:09  loss = 4.3494e-04  error = 1.4230e-01  l1 = 0.977571  l2 = 0.004018\n",
            "nt_epoch =    620  elapsed = 02:10  loss = 4.2664e-04  error = 1.3986e-01  l1 = 0.977671  l2 = 0.004002\n",
            "nt_epoch =    630  elapsed = 02:10  loss = 4.1387e-04  error = 1.3406e-01  l1 = 0.978039  l2 = 0.003967\n",
            "nt_epoch =    640  elapsed = 02:11  loss = 3.9536e-04  error = 1.2589e-01  l1 = 0.978565  l2 = 0.003916\n",
            "nt_epoch =    650  elapsed = 02:12  loss = 3.8593e-04  error = 1.2429e-01  l1 = 0.981028  l2 = 0.003914\n",
            "nt_epoch =    660  elapsed = 02:13  loss = 3.6977e-04  error = 1.1794e-01  l1 = 0.983975  l2 = 0.003883\n",
            "nt_epoch =    670  elapsed = 02:13  loss = 3.5404e-04  error = 1.0902e-01  l1 = 0.986621  l2 = 0.003835\n",
            "nt_epoch =    680  elapsed = 02:14  loss = 3.4587e-04  error = 1.0870e-01  l1 = 0.986583  l2 = 0.003832\n",
            "nt_epoch =    690  elapsed = 02:15  loss = 3.3574e-04  error = 9.7741e-02  l1 = 0.989604  l2 = 0.003772\n",
            "nt_epoch =    700  elapsed = 02:16  loss = 3.3032e-04  error = 9.5591e-02  l1 = 0.988987  l2 = 0.003757\n",
            "nt_epoch =    710  elapsed = 02:16  loss = 3.2505e-04  error = 9.3289e-02  l1 = 0.988222  l2 = 0.003740\n",
            "nt_epoch =    720  elapsed = 02:17  loss = 3.1893e-04  error = 9.3463e-02  l1 = 0.988216  l2 = 0.003741\n",
            "nt_epoch =    730  elapsed = 02:18  loss = 3.1159e-04  error = 9.2840e-02  l1 = 0.988094  l2 = 0.003736\n",
            "nt_epoch =    740  elapsed = 02:19  loss = 3.0835e-04  error = 9.0973e-02  l1 = 0.989097  l2 = 0.003728\n",
            "nt_epoch =    750  elapsed = 02:19  loss = 3.0501e-04  error = 8.9678e-02  l1 = 0.988718  l2 = 0.003718\n",
            "nt_epoch =    760  elapsed = 02:20  loss = 3.0158e-04  error = 8.6856e-02  l1 = 0.988924  l2 = 0.003701\n",
            "nt_epoch =    770  elapsed = 02:21  loss = 2.9709e-04  error = 8.7173e-02  l1 = 0.989656  l2 = 0.003705\n",
            "nt_epoch =    780  elapsed = 02:21  loss = 2.9322e-04  error = 8.4950e-02  l1 = 0.989905  l2 = 0.003692\n",
            "nt_epoch =    790  elapsed = 02:22  loss = 2.8995e-04  error = 8.2099e-02  l1 = 0.991208  l2 = 0.003678\n",
            "nt_epoch =    800  elapsed = 02:23  loss = 2.8303e-04  error = 8.2453e-02  l1 = 0.990563  l2 = 0.003678\n",
            "nt_epoch =    810  elapsed = 02:24  loss = 2.8030e-04  error = 8.0731e-02  l1 = 0.990243  l2 = 0.003666\n",
            "nt_epoch =    820  elapsed = 02:24  loss = 2.7459e-04  error = 7.8508e-02  l1 = 0.990548  l2 = 0.003653\n",
            "nt_epoch =    830  elapsed = 02:25  loss = 2.6815e-04  error = 7.2770e-02  l1 = 0.990572  l2 = 0.003616\n",
            "nt_epoch =    840  elapsed = 02:26  loss = 2.6646e-04  error = 7.1513e-02  l1 = 0.990482  l2 = 0.003608\n",
            "nt_epoch =    850  elapsed = 02:27  loss = 2.6340e-04  error = 6.9575e-02  l1 = 0.989949  l2 = 0.003594\n",
            "nt_epoch =    860  elapsed = 02:27  loss = 2.5905e-04  error = 6.4843e-02  l1 = 0.989484  l2 = 0.003562\n",
            "nt_epoch =    870  elapsed = 02:28  loss = 2.5359e-04  error = 6.5382e-02  l1 = 0.988561  l2 = 0.003563\n",
            "nt_epoch =    880  elapsed = 02:29  loss = 2.5141e-04  error = 6.4410e-02  l1 = 0.988276  l2 = 0.003556\n",
            "nt_epoch =    890  elapsed = 02:30  loss = 2.5087e-04  error = 6.3306e-02  l1 = 0.988423  l2 = 0.003549\n",
            "nt_epoch =    900  elapsed = 02:30  loss = 2.4933e-04  error = 6.0764e-02  l1 = 0.988442  l2 = 0.003533\n",
            "nt_epoch =    910  elapsed = 02:31  loss = 2.4731e-04  error = 5.9988e-02  l1 = 0.988365  l2 = 0.003528\n",
            "nt_epoch =    920  elapsed = 02:32  loss = 2.4192e-04  error = 5.7553e-02  l1 = 0.987530  l2 = 0.003510\n",
            "nt_epoch =    930  elapsed = 02:33  loss = 2.3796e-04  error = 5.4173e-02  l1 = 0.987698  l2 = 0.003489\n",
            "nt_epoch =    940  elapsed = 02:33  loss = 2.3606e-04  error = 5.2249e-02  l1 = 0.987704  l2 = 0.003477\n",
            "nt_epoch =    950  elapsed = 02:34  loss = 2.3499e-04  error = 5.2371e-02  l1 = 0.987540  l2 = 0.003477\n",
            "nt_epoch =    960  elapsed = 02:35  loss = 2.3331e-04  error = 5.2651e-02  l1 = 0.987840  l2 = 0.003480\n",
            "nt_epoch =    970  elapsed = 02:36  loss = 2.3635e-04  error = 5.3202e-02  l1 = 0.987503  l2 = 0.003482\n",
            "nt_epoch =    980  elapsed = 02:36  loss = 2.3004e-04  error = 5.3266e-02  l1 = 0.988165  l2 = 0.003485\n",
            "nt_epoch =    990  elapsed = 02:37  loss = 2.3981e-04  error = 5.6409e-02  l1 = 0.987052  l2 = 0.003501\n",
            "==================\n",
            "Training finished (epoch 100): duration = 02:38  error = 5.4180e-02  l1 = 0.988259  l2 = 0.003491\n",
            "l1:  0.9835344\n",
            "l2:  0.0033028587\n",
            "l1_noise:  0.98825926\n",
            "l2_noise:  0.0034906487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-y6mkKpP5M8",
        "lines_to_next_cell": 0,
        "outputId": "9719067e-b793-4b30-b609-cc000923bbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "plot_ide_cont_results(X_star, u_pred, X_u_train, u_train,\n",
        "  Exact_u, X, T, x, t, lambda_1_pred, lambda_1_pred_noise, lambda_2_pred, lambda_2_pred_noise)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 388.543x336.186 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcY8EfT1w1ev"
      },
      "source": [
        "# 4. Discrete Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFBJUhYqw1ew"
      },
      "source": [
        "$$u_t + \\lambda_1 u u_x - \\lambda_2 u_{xx} = 0$$\n",
        "\n",
        "With $\\lambda_1$ and $\\lambda_2$ real parameters of the differential operator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKxgAhrTw1ex"
      },
      "source": [
        "Approximating $u(t,x)$ with a deep NN, we define the PINN:\n",
        "$$f := u_t + \\lambda_1 u u_x - \\lambda_2 u_{xx}.$$\n",
        "\n",
        "We train the shared parameters between the deep NN and the PINN minimizing the loss:\n",
        "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_u}|f(t_u^i,x_u^i)|^2,$$\n",
        "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ respectively the trainring data on $u(t,x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGrMDRc3w1ex"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOuJ6DV1w1ey",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Data size on initial condition on u\n",
        "N_0 = 199\n",
        "N_1 = 201\n",
        "# DeepNN topology (1-sized input [x], 3 hidden layer of 50-width, q-sized output defined later [u_1^n(x), ..., u_{q+1}^n(x)]\n",
        "layers = [1, 50, 50, 50, 0]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "tf_epochs = 100\n",
        "tf_optimizer = tf.keras.optimizers.Adam(\n",
        "  lr=0.001,\n",
        "  beta_1=0.9,\n",
        "  beta_2=0.999,\n",
        "  epsilon=1e-08)\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "nt_epochs = 2000\n",
        "nt_config = Struct()\n",
        "nt_config.learningRate = 0.8\n",
        "nt_config.maxIter = nt_epochs\n",
        "nt_config.nCorrection = 50\n",
        "nt_config.tolFun = 1.0 * np.finfo(float).eps\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRGW4IW0w1e0"
      },
      "source": [
        "## PINN class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYMIf2_Uw1e0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yiB3TOYw1e1"
      },
      "source": [
        "\n",
        "class PhysicsInformedNN(object):\n",
        "  def __init__(self, layers, optimizer, logger, dt, lb, ub, q, IRK_alpha, IRK_beta):\n",
        "    self.lb = lb\n",
        "    self.ub = ub\n",
        "\n",
        "    self.dt = dt\n",
        "\n",
        "    self.q = max(q,1)\n",
        "    self.IRK_alpha = IRK_alpha\n",
        "    self.IRK_beta = IRK_beta\n",
        "\n",
        "    # Descriptive Keras model [2, 50, …, 50, q+1]\n",
        "    self.U_model = tf.keras.Sequential()\n",
        "    self.U_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    self.U_model.add(tf.keras.layers.Lambda(\n",
        "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:]:\n",
        "        self.U_model.add(tf.keras.layers.Dense(\n",
        "          width, activation=tf.nn.tanh,\n",
        "          kernel_initializer='glorot_normal'))\n",
        "\n",
        "    # Computing the sizes of weights/biases for future decomposition\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    for i, width in enumerate(layers):\n",
        "      if i != 1:\n",
        "        self.sizes_w.append(int(width * layers[1]))\n",
        "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "    self.dtype = tf.float32\n",
        "\n",
        "    self.optimizer = optimizer\n",
        "    self.logger = logger\n",
        "\n",
        "  def __autograd(self, U, x, dummy):\n",
        "    # Using the new GradientTape paradigm of TF2.0,\n",
        "    # which keeps track of operations to get the gradient at runtime\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Watching the two inputs we’ll need later, x and t\n",
        "      tape.watch(x)\n",
        "      tape.watch(dummy)\n",
        "\n",
        "      # Getting the prediction\n",
        "      U = self.U_model(x) # shape=(len(x), q)\n",
        "\n",
        "      # Deriving INSIDE the tape (2-step-dummy grad technique because U is a mat)\n",
        "      g_U = tape.gradient(U, x, output_gradients=dummy)\n",
        "      U_x = tape.gradient(g_U, dummy)\n",
        "      g_U_x = tape.gradient(U_x, x, output_gradients=dummy)\n",
        "    \n",
        "    # Doing the last one outside the with, to optimize performance\n",
        "    # Impossible to do for the earlier grad, because they’re needed after\n",
        "    U_xx = tape.gradient(g_U_x, dummy)\n",
        "\n",
        "    # Letting the tape go\n",
        "    del tape\n",
        "    return U_x, U_xx\n",
        "\n",
        "  def U_0_model(self, x, customDummy=None):\n",
        "    U = self.U_model(x)\n",
        "    if customDummy != None:\n",
        "      dummy = customDummy\n",
        "    else:\n",
        "      dummy = self.dummy_x_0\n",
        "    U_x, U_xx = self.__autograd(U, x, dummy)\n",
        "\n",
        "    # Buidling the PINNs\n",
        "    l1 = self.lambda_1\n",
        "    l2 = tf.exp(self.lambda_2)\n",
        "    N = l1*U*U_x - l2*U_xx # shape=(len(x), q)\n",
        "    return U + self.dt*tf.matmul(N, self.IRK_alpha.T)\n",
        "\n",
        "  def U_1_model(self, x, customDummy=None):\n",
        "    U = self.U_model(x)\n",
        "    #dummy = customDummy or self.dummy_x_1\n",
        "    if customDummy != None:\n",
        "      dummy = customDummy\n",
        "    else:\n",
        "      dummy = self.dummy_x_1\n",
        "    U_x, U_xx = self.__autograd(U, x, dummy)\n",
        "\n",
        "    # Buidling the PINNs, shape = (len(x), q+1), IRK shape = (q, q+1)\n",
        "    l1 = self.lambda_1\n",
        "    l2 = tf.exp(self.lambda_2)\n",
        "    N = -l1*U*U_x + l2*U_xx # shape=(len(x), q)\n",
        "    return U + self.dt*tf.matmul(N, (self.IRK_beta - self.IRK_alpha).T)\n",
        "\n",
        "  # Defining custom loss\n",
        "  def __loss(self, x_0, u_0, x_1, u_1):\n",
        "    u_0_pred = self.U_0_model(x_0)\n",
        "    u_1_pred = self.U_1_model(x_1)\n",
        "    return tf.reduce_sum(tf.square(u_0_pred - u_0)) + \\\n",
        "      tf.reduce_sum(tf.square(u_1_pred - u_1))\n",
        "\n",
        "  def __grad(self, x_0, u_0, x_1, u_1):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.__loss(x_0, u_0, x_1, u_1)\n",
        "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "\n",
        "  def __wrap_training_variables(self):\n",
        "    var = self.U_model.trainable_variables\n",
        "    var.extend([self.lambda_1, self.lambda_2])\n",
        "    return var\n",
        "\n",
        "  def get_weights(self):\n",
        "      w = []\n",
        "      for layer in self.U_model.layers[1:]:\n",
        "        weights_biases = layer.get_weights()\n",
        "        weights = weights_biases[0].flatten()\n",
        "        biases = weights_biases[1]\n",
        "        w.extend(weights)\n",
        "        w.extend(biases)\n",
        "      w.extend(self.lambda_1.numpy())\n",
        "      w.extend(self.lambda_2.numpy())\n",
        "      return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.U_model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "    self.lambda_1.assign([w[-2]])\n",
        "    self.lambda_2.assign([w[-1]])\n",
        "\n",
        "  def get_params(self, numpy=False):\n",
        "    l1 = self.lambda_1\n",
        "    l2 = tf.exp(self.lambda_2)\n",
        "    if numpy:\n",
        "      return l1.numpy()[0], l2.numpy()[0]\n",
        "    return l1, l2\n",
        "\n",
        "  def summary(self):\n",
        "    return self.U_model.summary()\n",
        "\n",
        "  def __createDummy(self, x):\n",
        "    return tf.ones([x.shape[0], self.q], dtype=self.dtype)\n",
        "\n",
        "  # The training function\n",
        "  def fit(self, x_0, u_0, x_1, u_1, tf_epochs=1):\n",
        "    self.logger.log_train_start(self)\n",
        "\n",
        "    # Creating the tensors\n",
        "    x_0 = tf.convert_to_tensor(x_0, dtype=self.dtype)\n",
        "    u_0 = tf.convert_to_tensor(u_0, dtype=self.dtype)\n",
        "    x_1 = tf.convert_to_tensor(x_1, dtype=self.dtype)\n",
        "    u_1 = tf.convert_to_tensor(u_1, dtype=self.dtype)\n",
        "\n",
        "    self.lambda_1 = tf.Variable([0.0], dtype=self.dtype)\n",
        "    self.lambda_2 = tf.Variable([-6.0], dtype=self.dtype)\n",
        "\n",
        "    # Creating dummy tensors for the gradients\n",
        "    self.dummy_x_0 = self.__createDummy(x_0)\n",
        "    self.dummy_x_1 = self.__createDummy(x_1)\n",
        "\n",
        "    def log_train_epoch(epoch, loss, is_iter):\n",
        "      l1, l2 = self.get_params(numpy=True)\n",
        "      custom = f\"l1 = {l1:5f}  l2 = {l2:8f}\"\n",
        "      self.logger.log_train_epoch(epoch, loss, custom, is_iter)\n",
        "\n",
        "    self.logger.log_train_opt(\"Adam\")\n",
        "    for epoch in range(tf_epochs):\n",
        "      # Optimization step\n",
        "      loss_value, grads = self.__grad(x_0, u_0, x_1, u_1)\n",
        "      self.optimizer.apply_gradients(\n",
        "        zip(grads, self.__wrap_training_variables()))\n",
        "      log_train_epoch(epoch, loss_value, False)\n",
        "    \n",
        "    self.logger.log_train_opt(\"LBFGS\")\n",
        "    def loss_and_flat_grad(w):\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        tape.watch(self.lambda_1)\n",
        "        tape.watch(self.lambda_2)\n",
        "        loss_value = self.__loss(x_0, u_0, x_1, u_1)\n",
        "      grad = tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "      grad_flat = []\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat =  tf.concat(grad_flat, 0)\n",
        "      return loss_value, grad_flat\n",
        "    # tfp.optimizer.lbfgs_minimize(\n",
        "    #   loss_and_flat_grad,\n",
        "    #   initial_position=self.get_weights(),\n",
        "    #   num_correction_pairs=nt_config.nCorrection,\n",
        "    #   max_iterations=nt_config.maxIter,\n",
        "    #   f_relative_tolerance=nt_config.tolFun,\n",
        "    #   tolerance=nt_config.tolFun,\n",
        "    #   parallel_iterations=6)\n",
        "    lbfgs(loss_and_flat_grad,\n",
        "      self.get_weights(),\n",
        "      nt_config, Struct(), True, log_train_epoch)\n",
        "    \n",
        "    l1, l2 = self.get_params(numpy=True)\n",
        "    self.logger.log_train_end(tf_epochs, f\"l1 = {l1:5f}  l2 = {l2:8f}\")\n",
        "\n",
        "  def predict(self, x_star):\n",
        "    x_star = tf.convert_to_tensor(x_star, dtype=self.dtype)\n",
        "    dummy = self.__createDummy(x_star)\n",
        "    U_0_star = self.U_0_model(x_star, dummy)\n",
        "    U_1_star = self.U_1_model(x_star, dummy)\n",
        "    return U_0_star, U_1_star"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFS_u67iw1e2"
      },
      "source": [
        "## Training and plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU5VfXKsw1e3",
        "lines_to_next_cell": 2,
        "outputId": "4efb2baf-7293-44e6-9ffb-9ed22d39d152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Setup\n",
        "lb = np.array([-1.0])\n",
        "ub = np.array([1.0])\n",
        "idx_t_0 = 10\n",
        "skip = 80\n",
        "idx_t_1 = idx_t_0 + skip\n",
        "\n",
        "# Getting the data\n",
        "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
        "x_0, u_0, x_1, u_1, x_star, t_star, dt, q, \\\n",
        "  Exact_u, IRK_alpha, IRK_beta = prep_data(path, N_0=N_0, N_1=N_1,\n",
        "  lb=lb, ub=ub, noise=0.0, idx_t_0=idx_t_0, idx_t_1=idx_t_1)\n",
        "lambdas_star = (1.0, 0.01/np.pi)\n",
        "\n",
        "# Setting the output layer dynamically\n",
        "layers[-1] = q\n",
        " \n",
        "# Creating the model and training\n",
        "logger = Logger(frequency=10)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, dt, lb, ub, q, IRK_alpha, IRK_beta)\n",
        "def error():\n",
        "  l1, l2 = pinn.get_params(numpy=True)\n",
        "  l1_star, l2_star = lambdas_star\n",
        "  error_lambda_1 = np.abs(l1 - l1_star) / l1_star\n",
        "  error_lambda_2 = np.abs(l2 - l2_star) / l2_star\n",
        "  return (error_lambda_1 + error_lambda_2) / 2\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(x_0, u_0, x_1, u_1, tf_epochs)\n",
        "\n",
        "# Getting the model predictions\n",
        "U_0_pred, U_1_pred = pinn.predict(x_star)\n",
        "lambda_1_pred, lambda_2_pred = pinn.get_params(numpy=True)\n",
        "\n",
        "# Noisy case (same as before with a different noise)\n",
        "x_0, u_0, x_1, u_1, x_star, t_star, dt, q, \\\n",
        "  Exact_u, IRK_alpha, IRK_beta = prep_data(path, N_0=N_0, N_1=N_1,\n",
        "  lb=lb, ub=ub, noise=0.01, idx_t_0=idx_t_0, idx_t_1=idx_t_1)\n",
        "layers[-1] = q\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, dt, lb, ub, q, IRK_alpha, IRK_beta)\n",
        "pinn.fit(x_0, u_0, x_1, u_1, tf_epochs)\n",
        "U_0_pred, U_1_pred = pinn.predict(x_star)\n",
        "lambda_1_pred_noisy, lambda_2_pred_noisy = pinn.get_params(numpy=True)\n",
        "\n",
        "print(\"l1: \", lambda_1_pred)\n",
        "print(\"l2: \", lambda_2_pred)\n",
        "print(\"noisy l1: \", lambda_1_pred_noisy)\n",
        "print(\"noisy l2: \", lambda_2_pred_noisy)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n",
            "Eager execution: True\n",
            "GPU-accerelated: True\n",
            "\n",
            "Training started\n",
            "================\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_8 (Lambda)            (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 81)                4131      \n",
            "=================================================================\n",
            "Total params: 9,331\n",
            "Trainable params: 9,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "—— Starting Adam optimization ——\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tf_epoch =      0  elapsed = 00:00  loss = 1.1637e+04  error = 6.1075e-01  l1 = -0.001000  l2 = 0.002481\n",
            "tf_epoch =     10  elapsed = 00:00  loss = 9.7364e+03  error = 6.1196e-01  l1 = -0.011166  l2 = 0.002506\n",
            "tf_epoch =     20  elapsed = 00:01  loss = 7.8780e+03  error = 6.1319e-01  l1 = -0.022270  l2 = 0.002533\n",
            "tf_epoch =     30  elapsed = 00:01  loss = 6.4392e+03  error = 6.1444e-01  l1 = -0.034734  l2 = 0.002565\n",
            "tf_epoch =     40  elapsed = 00:02  loss = 5.7867e+03  error = 6.1558e-01  l1 = -0.048203  l2 = 0.002601\n",
            "tf_epoch =     50  elapsed = 00:02  loss = 5.3044e+03  error = 6.1635e-01  l1 = -0.061398  l2 = 0.002638\n",
            "tf_epoch =     60  elapsed = 00:03  loss = 4.7344e+03  error = 6.1643e-01  l1 = -0.072777  l2 = 0.002674\n",
            "tf_epoch =     70  elapsed = 00:03  loss = 4.0728e+03  error = 6.1564e-01  l1 = -0.081171  l2 = 0.002705\n",
            "tf_epoch =     80  elapsed = 00:04  loss = 3.4432e+03  error = 6.1442e-01  l1 = -0.085179  l2 = 0.002726\n",
            "tf_epoch =     90  elapsed = 00:04  loss = 2.9441e+03  error = 6.1476e-01  l1 = -0.082740  l2 = 0.002716\n",
            "—— Starting LBFGS optimization ——\n",
            "nt_epoch =     10  elapsed = 00:05  loss = 1.3902e+03  error = 3.1653e-01  l1 = 0.489170  l2 = 0.002794\n",
            "nt_epoch =     20  elapsed = 00:06  loss = 7.1945e+02  error = 6.7863e-01  l1 = 0.404073  l2 = 0.005606\n",
            "nt_epoch =     30  elapsed = 00:07  loss = 5.4605e+02  error = 1.7527e+00  l1 = 0.611810  l2 = 0.013106\n",
            "nt_epoch =     40  elapsed = 00:07  loss = 3.7865e+02  error = 2.4398e+00  l1 = 0.981614  l2 = 0.018657\n",
            "nt_epoch =     50  elapsed = 00:08  loss = 2.9860e+02  error = 2.2146e+00  l1 = 0.997977  l2 = 0.017275\n",
            "nt_epoch =     60  elapsed = 00:09  loss = 2.2133e+02  error = 2.0980e+00  l1 = 1.029193  l2 = 0.016446\n",
            "nt_epoch =     70  elapsed = 00:10  loss = 1.6800e+02  error = 1.7878e+00  l1 = 0.979118  l2 = 0.014498\n",
            "nt_epoch =     80  elapsed = 00:10  loss = 1.3685e+02  error = 1.4599e+00  l1 = 0.936669  l2 = 0.012276\n",
            "nt_epoch =     90  elapsed = 00:11  loss = 1.2575e+02  error = 1.4338e+00  l1 = 0.946631  l2 = 0.012141\n",
            "nt_epoch =    100  elapsed = 00:12  loss = 1.1809e+02  error = 1.3328e+00  l1 = 0.952656  l2 = 0.011517\n",
            "nt_epoch =    110  elapsed = 00:13  loss = 1.0857e+02  error = 1.2575e+00  l1 = 0.971822  l2 = 0.011099\n",
            "nt_epoch =    120  elapsed = 00:14  loss = 1.0273e+02  error = 1.1703e+00  l1 = 0.976920  l2 = 0.010560\n",
            "nt_epoch =    130  elapsed = 00:14  loss = 9.7503e+01  error = 1.1130e+00  l1 = 0.982290  l2 = 0.010212\n",
            "nt_epoch =    140  elapsed = 00:15  loss = 9.5074e+01  error = 1.0718e+00  l1 = 0.983036  l2 = 0.009953\n",
            "nt_epoch =    150  elapsed = 00:16  loss = 9.1196e+01  error = 1.0408e+00  l1 = 0.989497  l2 = 0.009775\n",
            "nt_epoch =    160  elapsed = 00:17  loss = 8.7928e+01  error = 9.8358e-01  l1 = 0.984518  l2 = 0.009395\n",
            "nt_epoch =    170  elapsed = 00:17  loss = 8.4534e+01  error = 9.8520e-01  l1 = 0.995234  l2 = 0.009440\n",
            "nt_epoch =    180  elapsed = 00:18  loss = 7.9139e+01  error = 9.4947e-01  l1 = 0.978908  l2 = 0.009160\n",
            "nt_epoch =    190  elapsed = 00:19  loss = 6.8249e+01  error = 1.0076e+00  l1 = 1.002830  l2 = 0.009588\n",
            "nt_epoch =    200  elapsed = 00:20  loss = 6.0439e+01  error = 1.0436e+00  l1 = 1.009898  l2 = 0.009795\n",
            "nt_epoch =    210  elapsed = 00:20  loss = 5.2898e+01  error = 1.0146e+00  l1 = 1.006244  l2 = 0.009622\n",
            "nt_epoch =    220  elapsed = 00:21  loss = 4.7252e+01  error = 9.7811e-01  l1 = 1.000803  l2 = 0.009407\n",
            "nt_epoch =    230  elapsed = 00:22  loss = 4.2234e+01  error = 9.1772e-01  l1 = 0.998210  l2 = 0.009020\n",
            "nt_epoch =    240  elapsed = 00:23  loss = 3.8252e+01  error = 9.0046e-01  l1 = 0.998060  l2 = 0.008909\n",
            "nt_epoch =    250  elapsed = 00:24  loss = 3.5332e+01  error = 8.8527e-01  l1 = 0.998581  l2 = 0.008814\n",
            "nt_epoch =    260  elapsed = 00:24  loss = 3.3141e+01  error = 8.5855e-01  l1 = 0.989653  l2 = 0.008616\n",
            "nt_epoch =    270  elapsed = 00:25  loss = 3.0123e+01  error = 8.3663e-01  l1 = 0.993062  l2 = 0.008487\n",
            "nt_epoch =    280  elapsed = 00:26  loss = 2.7786e+01  error = 7.9142e-01  l1 = 0.985002  l2 = 0.008174\n",
            "nt_epoch =    290  elapsed = 00:27  loss = 2.5325e+01  error = 7.4008e-01  l1 = 0.984567  l2 = 0.007845\n",
            "nt_epoch =    300  elapsed = 00:27  loss = 2.3008e+01  error = 6.9181e-01  l1 = 0.979552  l2 = 0.007522\n",
            "nt_epoch =    310  elapsed = 00:28  loss = 2.1339e+01  error = 6.6759e-01  l1 = 0.980241  l2 = 0.007370\n",
            "nt_epoch =    320  elapsed = 00:29  loss = 1.9938e+01  error = 6.4218e-01  l1 = 0.985796  l2 = 0.007226\n",
            "nt_epoch =    330  elapsed = 00:30  loss = 1.8785e+01  error = 6.3561e-01  l1 = 0.988383  l2 = 0.007193\n",
            "nt_epoch =    340  elapsed = 00:31  loss = 1.7751e+01  error = 6.2630e-01  l1 = 0.989228  l2 = 0.007136\n",
            "nt_epoch =    350  elapsed = 00:31  loss = 1.7155e+01  error = 6.1503e-01  l1 = 0.991228  l2 = 0.007071\n",
            "nt_epoch =    360  elapsed = 00:32  loss = 1.6529e+01  error = 6.0417e-01  l1 = 0.992716  l2 = 0.007006\n",
            "nt_epoch =    370  elapsed = 00:33  loss = 1.6110e+01  error = 5.9083e-01  l1 = 0.988644  l2 = 0.006908\n",
            "nt_epoch =    380  elapsed = 00:34  loss = 1.5509e+01  error = 5.8071e-01  l1 = 0.991549  l2 = 0.006853\n",
            "nt_epoch =    390  elapsed = 00:34  loss = 1.4801e+01  error = 5.5799e-01  l1 = 0.991986  l2 = 0.006710\n",
            "nt_epoch =    400  elapsed = 00:35  loss = 1.4248e+01  error = 5.5039e-01  l1 = 0.992114  l2 = 0.006662\n",
            "nt_epoch =    410  elapsed = 00:36  loss = 1.3842e+01  error = 5.4378e-01  l1 = 0.993113  l2 = 0.006623\n",
            "nt_epoch =    420  elapsed = 00:37  loss = 1.3306e+01  error = 5.2470e-01  l1 = 0.991343  l2 = 0.006496\n",
            "nt_epoch =    430  elapsed = 00:38  loss = 1.2760e+01  error = 5.0750e-01  l1 = 0.990423  l2 = 0.006383\n",
            "nt_epoch =    440  elapsed = 00:38  loss = 1.2166e+01  error = 4.9366e-01  l1 = 0.987897  l2 = 0.006287\n",
            "nt_epoch =    450  elapsed = 00:39  loss = 1.1728e+01  error = 4.8234e-01  l1 = 0.985541  l2 = 0.006208\n",
            "nt_epoch =    460  elapsed = 00:40  loss = 1.1351e+01  error = 4.7430e-01  l1 = 0.986475  l2 = 0.006160\n",
            "nt_epoch =    470  elapsed = 00:41  loss = 1.0947e+01  error = 4.5574e-01  l1 = 0.981111  l2 = 0.006024\n",
            "nt_epoch =    480  elapsed = 00:41  loss = 1.0535e+01  error = 4.4807e-01  l1 = 0.980892  l2 = 0.005975\n",
            "nt_epoch =    490  elapsed = 00:42  loss = 1.0068e+01  error = 4.3418e-01  l1 = 0.980558  l2 = 0.005885\n",
            "nt_epoch =    500  elapsed = 00:43  loss = 9.5895e+00  error = 4.1523e-01  l1 = 0.978957  l2 = 0.005760\n",
            "nt_epoch =    510  elapsed = 00:44  loss = 9.2409e+00  error = 4.0158e-01  l1 = 0.981024  l2 = 0.005679\n",
            "nt_epoch =    520  elapsed = 00:45  loss = 8.9729e+00  error = 3.9897e-01  l1 = 0.981318  l2 = 0.005664\n",
            "nt_epoch =    530  elapsed = 00:45  loss = 8.6340e+00  error = 3.8463e-01  l1 = 0.981193  l2 = 0.005572\n",
            "nt_epoch =    540  elapsed = 00:46  loss = 8.4458e+00  error = 3.6894e-01  l1 = 0.981394  l2 = 0.005473\n",
            "nt_epoch =    550  elapsed = 00:47  loss = 8.0742e+00  error = 3.6493e-01  l1 = 0.981561  l2 = 0.005448\n",
            "nt_epoch =    560  elapsed = 00:48  loss = 7.8507e+00  error = 3.5998e-01  l1 = 0.980603  l2 = 0.005413\n",
            "nt_epoch =    570  elapsed = 00:48  loss = 7.6385e+00  error = 3.5226e-01  l1 = 0.982985  l2 = 0.005371\n",
            "nt_epoch =    580  elapsed = 00:49  loss = 7.3613e+00  error = 3.4532e-01  l1 = 0.981209  l2 = 0.005322\n",
            "nt_epoch =    590  elapsed = 00:50  loss = 7.1405e+00  error = 3.4052e-01  l1 = 0.981455  l2 = 0.005292\n",
            "nt_epoch =    600  elapsed = 00:51  loss = 6.9824e+00  error = 3.3504e-01  l1 = 0.982640  l2 = 0.005261\n",
            "nt_epoch =    610  elapsed = 00:51  loss = 6.8054e+00  error = 3.2880e-01  l1 = 0.981014  l2 = 0.005216\n",
            "nt_epoch =    620  elapsed = 00:52  loss = 6.6655e+00  error = 3.2990e-01  l1 = 0.980387  l2 = 0.005221\n",
            "nt_epoch =    630  elapsed = 00:53  loss = 6.5139e+00  error = 3.2785e-01  l1 = 0.983341  l2 = 0.005217\n",
            "nt_epoch =    640  elapsed = 00:54  loss = 6.3479e+00  error = 3.2558e-01  l1 = 0.981944  l2 = 0.005198\n",
            "nt_epoch =    650  elapsed = 00:55  loss = 6.1809e+00  error = 3.2337e-01  l1 = 0.982910  l2 = 0.005187\n",
            "nt_epoch =    660  elapsed = 00:55  loss = 6.0004e+00  error = 3.2405e-01  l1 = 0.981498  l2 = 0.005187\n",
            "nt_epoch =    670  elapsed = 00:56  loss = 5.8468e+00  error = 3.2326e-01  l1 = 0.982937  l2 = 0.005187\n",
            "nt_epoch =    680  elapsed = 00:57  loss = 5.7290e+00  error = 3.1954e-01  l1 = 0.982029  l2 = 0.005160\n",
            "nt_epoch =    690  elapsed = 00:58  loss = 5.6030e+00  error = 3.1857e-01  l1 = 0.981740  l2 = 0.005153\n",
            "nt_epoch =    700  elapsed = 00:58  loss = 5.6113e+00  error = 3.1179e-01  l1 = 0.978937  l2 = 0.005101\n",
            "nt_epoch =    710  elapsed = 00:59  loss = 5.3071e+00  error = 3.1257e-01  l1 = 0.978922  l2 = 0.005106\n",
            "nt_epoch =    720  elapsed = 01:00  loss = 5.1713e+00  error = 3.1426e-01  l1 = 0.979269  l2 = 0.005118\n",
            "nt_epoch =    730  elapsed = 01:01  loss = 5.0535e+00  error = 3.1725e-01  l1 = 0.976510  l2 = 0.005128\n",
            "nt_epoch =    740  elapsed = 01:02  loss = 4.9323e+00  error = 3.1762e-01  l1 = 0.976686  l2 = 0.005131\n",
            "nt_epoch =    750  elapsed = 01:02  loss = 4.8326e+00  error = 3.1783e-01  l1 = 0.977280  l2 = 0.005134\n",
            "nt_epoch =    760  elapsed = 01:03  loss = 4.7107e+00  error = 3.1483e-01  l1 = 0.975958  l2 = 0.005111\n",
            "nt_epoch =    770  elapsed = 01:04  loss = 4.5970e+00  error = 3.1173e-01  l1 = 0.975854  l2 = 0.005091\n",
            "nt_epoch =    780  elapsed = 01:05  loss = 4.4783e+00  error = 3.1034e-01  l1 = 0.975132  l2 = 0.005080\n",
            "nt_epoch =    790  elapsed = 01:05  loss = 4.3910e+00  error = 3.0998e-01  l1 = 0.976247  l2 = 0.005081\n",
            "nt_epoch =    800  elapsed = 01:06  loss = 4.3163e+00  error = 3.0867e-01  l1 = 0.976022  l2 = 0.005072\n",
            "nt_epoch =    810  elapsed = 01:07  loss = 4.1607e+00  error = 3.1025e-01  l1 = 0.975801  l2 = 0.005081\n",
            "nt_epoch =    820  elapsed = 01:08  loss = 4.0839e+00  error = 3.1196e-01  l1 = 0.977159  l2 = 0.005096\n",
            "nt_epoch =    830  elapsed = 01:08  loss = 4.0095e+00  error = 3.1249e-01  l1 = 0.976252  l2 = 0.005097\n",
            "nt_epoch =    840  elapsed = 01:09  loss = 3.9077e+00  error = 3.1102e-01  l1 = 0.977102  l2 = 0.005090\n",
            "nt_epoch =    850  elapsed = 01:10  loss = 3.8315e+00  error = 3.0959e-01  l1 = 0.977820  l2 = 0.005083\n",
            "nt_epoch =    860  elapsed = 01:11  loss = 3.7871e+00  error = 3.0913e-01  l1 = 0.978670  l2 = 0.005083\n",
            "nt_epoch =    870  elapsed = 01:12  loss = 3.7271e+00  error = 3.0887e-01  l1 = 0.977547  l2 = 0.005078\n",
            "nt_epoch =    880  elapsed = 01:12  loss = 3.6727e+00  error = 3.0874e-01  l1 = 0.979495  l2 = 0.005083\n",
            "nt_epoch =    890  elapsed = 01:13  loss = 3.6013e+00  error = 3.0737e-01  l1 = 0.978024  l2 = 0.005070\n",
            "nt_epoch =    900  elapsed = 01:14  loss = 3.5329e+00  error = 3.0627e-01  l1 = 0.978542  l2 = 0.005065\n",
            "nt_epoch =    910  elapsed = 01:15  loss = 3.4792e+00  error = 3.0511e-01  l1 = 0.978699  l2 = 0.005058\n",
            "nt_epoch =    920  elapsed = 01:15  loss = 3.4083e+00  error = 3.0329e-01  l1 = 0.979732  l2 = 0.005049\n",
            "nt_epoch =    930  elapsed = 01:16  loss = 3.3594e+00  error = 3.0196e-01  l1 = 0.979191  l2 = 0.005039\n",
            "nt_epoch =    940  elapsed = 01:17  loss = 3.3039e+00  error = 2.9935e-01  l1 = 0.978920  l2 = 0.005022\n",
            "nt_epoch =    950  elapsed = 01:18  loss = 3.2483e+00  error = 2.9878e-01  l1 = 0.980066  l2 = 0.005022\n",
            "nt_epoch =    960  elapsed = 01:19  loss = 3.1871e+00  error = 2.9822e-01  l1 = 0.979688  l2 = 0.005017\n",
            "nt_epoch =    970  elapsed = 01:19  loss = 3.1303e+00  error = 2.9688e-01  l1 = 0.979516  l2 = 0.005008\n",
            "nt_epoch =    980  elapsed = 01:20  loss = 3.0994e+00  error = 2.9623e-01  l1 = 0.979584  l2 = 0.005004\n",
            "nt_epoch =    990  elapsed = 01:21  loss = 3.0533e+00  error = 2.9471e-01  l1 = 0.980630  l2 = 0.004998\n",
            "nt_epoch =   1000  elapsed = 01:22  loss = 3.0071e+00  error = 2.9126e-01  l1 = 0.979862  l2 = 0.004973\n",
            "nt_epoch =   1010  elapsed = 01:22  loss = 2.9579e+00  error = 2.8922e-01  l1 = 0.980259  l2 = 0.004961\n",
            "nt_epoch =   1020  elapsed = 01:23  loss = 2.9053e+00  error = 2.8622e-01  l1 = 0.979787  l2 = 0.004941\n",
            "nt_epoch =   1030  elapsed = 01:24  loss = 2.8504e+00  error = 2.8200e-01  l1 = 0.981219  l2 = 0.004919\n",
            "nt_epoch =   1040  elapsed = 01:25  loss = 2.8072e+00  error = 2.8000e-01  l1 = 0.980796  l2 = 0.004904\n",
            "nt_epoch =   1050  elapsed = 01:25  loss = 2.7541e+00  error = 2.7785e-01  l1 = 0.981923  l2 = 0.004894\n",
            "nt_epoch =   1060  elapsed = 01:26  loss = 2.7040e+00  error = 2.7477e-01  l1 = 0.981279  l2 = 0.004873\n",
            "nt_epoch =   1070  elapsed = 01:27  loss = 2.6515e+00  error = 2.7135e-01  l1 = 0.981778  l2 = 0.004853\n",
            "nt_epoch =   1080  elapsed = 01:28  loss = 2.6271e+00  error = 2.6658e-01  l1 = 0.982582  l2 = 0.004825\n",
            "nt_epoch =   1090  elapsed = 01:28  loss = 2.5710e+00  error = 2.6360e-01  l1 = 0.982239  l2 = 0.004805\n",
            "nt_epoch =   1100  elapsed = 01:29  loss = 2.5223e+00  error = 2.5954e-01  l1 = 0.983185  l2 = 0.004782\n",
            "nt_epoch =   1110  elapsed = 01:30  loss = 2.4752e+00  error = 2.5475e-01  l1 = 0.984061  l2 = 0.004754\n",
            "nt_epoch =   1120  elapsed = 01:31  loss = 2.4316e+00  error = 2.5170e-01  l1 = 0.983420  l2 = 0.004733\n",
            "nt_epoch =   1130  elapsed = 01:31  loss = 2.3959e+00  error = 2.4808e-01  l1 = 0.984825  l2 = 0.004714\n",
            "nt_epoch =   1140  elapsed = 01:32  loss = 2.3478e+00  error = 2.4205e-01  l1 = 0.984997  l2 = 0.004676\n",
            "nt_epoch =   1150  elapsed = 01:33  loss = 2.3028e+00  error = 2.3872e-01  l1 = 0.984827  l2 = 0.004655\n",
            "nt_epoch =   1160  elapsed = 01:34  loss = 2.2728e+00  error = 2.3655e-01  l1 = 0.985812  l2 = 0.004644\n",
            "nt_epoch =   1170  elapsed = 01:35  loss = 2.2279e+00  error = 2.3244e-01  l1 = 0.986001  l2 = 0.004618\n",
            "nt_epoch =   1180  elapsed = 01:35  loss = 2.1830e+00  error = 2.2856e-01  l1 = 0.986931  l2 = 0.004597\n",
            "nt_epoch =   1190  elapsed = 01:36  loss = 2.1536e+00  error = 2.2673e-01  l1 = 0.986394  l2 = 0.004583\n",
            "nt_epoch =   1200  elapsed = 01:37  loss = 2.1075e+00  error = 2.2268e-01  l1 = 0.986286  l2 = 0.004557\n",
            "nt_epoch =   1210  elapsed = 01:38  loss = 2.0757e+00  error = 2.2080e-01  l1 = 0.987248  l2 = 0.004548\n",
            "nt_epoch =   1220  elapsed = 01:38  loss = 2.0398e+00  error = 2.1746e-01  l1 = 0.987629  l2 = 0.004528\n",
            "nt_epoch =   1230  elapsed = 01:39  loss = 2.0092e+00  error = 2.1453e-01  l1 = 0.987450  l2 = 0.004509\n",
            "nt_epoch =   1240  elapsed = 01:40  loss = 1.9703e+00  error = 2.1079e-01  l1 = 0.987846  l2 = 0.004486\n",
            "nt_epoch =   1250  elapsed = 01:41  loss = 1.9437e+00  error = 2.0915e-01  l1 = 0.986743  l2 = 0.004472\n",
            "nt_epoch =   1260  elapsed = 01:41  loss = 1.9066e+00  error = 2.0634e-01  l1 = 0.987701  l2 = 0.004458\n",
            "nt_epoch =   1270  elapsed = 01:42  loss = 1.8769e+00  error = 2.0398e-01  l1 = 0.988145  l2 = 0.004444\n",
            "nt_epoch =   1280  elapsed = 01:43  loss = 1.8532e+00  error = 2.0183e-01  l1 = 0.987899  l2 = 0.004429\n",
            "nt_epoch =   1290  elapsed = 01:44  loss = 1.8193e+00  error = 1.9641e-01  l1 = 0.988720  l2 = 0.004398\n",
            "nt_epoch =   1300  elapsed = 01:44  loss = 1.7916e+00  error = 1.9482e-01  l1 = 0.988411  l2 = 0.004386\n",
            "nt_epoch =   1310  elapsed = 01:45  loss = 1.7668e+00  error = 1.9149e-01  l1 = 0.988692  l2 = 0.004366\n",
            "nt_epoch =   1320  elapsed = 01:46  loss = 1.7432e+00  error = 1.8850e-01  l1 = 0.988478  l2 = 0.004346\n",
            "nt_epoch =   1330  elapsed = 01:47  loss = 1.7233e+00  error = 1.8756e-01  l1 = 0.988973  l2 = 0.004342\n",
            "nt_epoch =   1340  elapsed = 01:47  loss = 1.6965e+00  error = 1.8538e-01  l1 = 0.987767  l2 = 0.004324\n",
            "nt_epoch =   1350  elapsed = 01:48  loss = 1.6810e+00  error = 1.8164e-01  l1 = 0.988171  l2 = 0.004302\n",
            "nt_epoch =   1360  elapsed = 01:49  loss = 1.6673e+00  error = 1.7984e-01  l1 = 0.988033  l2 = 0.004290\n",
            "nt_epoch =   1370  elapsed = 01:50  loss = 1.6464e+00  error = 1.7765e-01  l1 = 0.987701  l2 = 0.004275\n",
            "nt_epoch =   1380  elapsed = 01:50  loss = 1.6275e+00  error = 1.7405e-01  l1 = 0.987964  l2 = 0.004253\n",
            "nt_epoch =   1390  elapsed = 01:51  loss = 1.6074e+00  error = 1.7171e-01  l1 = 0.988257  l2 = 0.004239\n",
            "nt_epoch =   1400  elapsed = 01:52  loss = 1.5906e+00  error = 1.7044e-01  l1 = 0.988209  l2 = 0.004231\n",
            "nt_epoch =   1410  elapsed = 01:53  loss = 1.5792e+00  error = 1.6883e-01  l1 = 0.988204  l2 = 0.004220\n",
            "nt_epoch =   1420  elapsed = 01:54  loss = 1.5652e+00  error = 1.6685e-01  l1 = 0.988436  l2 = 0.004208\n",
            "nt_epoch =   1430  elapsed = 01:54  loss = 1.5483e+00  error = 1.6145e-01  l1 = 0.988481  l2 = 0.004174\n",
            "nt_epoch =   1440  elapsed = 01:55  loss = 1.5364e+00  error = 1.5964e-01  l1 = 0.988325  l2 = 0.004162\n",
            "nt_epoch =   1450  elapsed = 01:56  loss = 1.5171e+00  error = 1.5757e-01  l1 = 0.988479  l2 = 0.004150\n",
            "nt_epoch =   1460  elapsed = 01:57  loss = 1.5042e+00  error = 1.5456e-01  l1 = 0.989070  l2 = 0.004132\n",
            "nt_epoch =   1470  elapsed = 01:57  loss = 1.4885e+00  error = 1.5272e-01  l1 = 0.989466  l2 = 0.004122\n",
            "nt_epoch =   1480  elapsed = 01:58  loss = 1.4715e+00  error = 1.5181e-01  l1 = 0.989098  l2 = 0.004115\n",
            "nt_epoch =   1490  elapsed = 01:59  loss = 1.4511e+00  error = 1.4728e-01  l1 = 0.990131  l2 = 0.004089\n",
            "nt_epoch =   1500  elapsed = 02:00  loss = 1.4330e+00  error = 1.4621e-01  l1 = 0.990095  l2 = 0.004082\n",
            "nt_epoch =   1510  elapsed = 02:00  loss = 1.4314e+00  error = 1.4354e-01  l1 = 0.989164  l2 = 0.004062\n",
            "nt_epoch =   1520  elapsed = 02:01  loss = 1.4060e+00  error = 1.4142e-01  l1 = 0.989462  l2 = 0.004050\n",
            "nt_epoch =   1530  elapsed = 02:02  loss = 1.3906e+00  error = 1.3809e-01  l1 = 0.990773  l2 = 0.004033\n",
            "nt_epoch =   1540  elapsed = 02:03  loss = 1.3745e+00  error = 1.3557e-01  l1 = 0.990281  l2 = 0.004015\n",
            "nt_epoch =   1550  elapsed = 02:03  loss = 1.3517e+00  error = 1.3185e-01  l1 = 0.990126  l2 = 0.003991\n",
            "nt_epoch =   1560  elapsed = 02:04  loss = 1.3412e+00  error = 1.3061e-01  l1 = 0.990229  l2 = 0.003983\n",
            "nt_epoch =   1570  elapsed = 02:05  loss = 1.3299e+00  error = 1.2822e-01  l1 = 0.990259  l2 = 0.003968\n",
            "nt_epoch =   1580  elapsed = 02:06  loss = 1.3148e+00  error = 1.2511e-01  l1 = 0.990481  l2 = 0.003949\n",
            "nt_epoch =   1590  elapsed = 02:06  loss = 1.2976e+00  error = 1.2463e-01  l1 = 0.989987  l2 = 0.003945\n",
            "nt_epoch =   1600  elapsed = 02:07  loss = 1.2840e+00  error = 1.2345e-01  l1 = 0.990063  l2 = 0.003937\n",
            "nt_epoch =   1610  elapsed = 02:08  loss = 1.2696e+00  error = 1.2098e-01  l1 = 0.990527  l2 = 0.003923\n",
            "nt_epoch =   1620  elapsed = 02:09  loss = 1.2588e+00  error = 1.1837e-01  l1 = 0.990099  l2 = 0.003905\n",
            "nt_epoch =   1630  elapsed = 02:09  loss = 1.2470e+00  error = 1.1828e-01  l1 = 0.990233  l2 = 0.003905\n",
            "nt_epoch =   1640  elapsed = 02:10  loss = 1.2328e+00  error = 1.1286e-01  l1 = 0.990786  l2 = 0.003872\n",
            "nt_epoch =   1650  elapsed = 02:11  loss = 1.2222e+00  error = 1.1166e-01  l1 = 0.990287  l2 = 0.003863\n",
            "nt_epoch =   1660  elapsed = 02:12  loss = 1.2070e+00  error = 1.0794e-01  l1 = 0.990254  l2 = 0.003839\n",
            "nt_epoch =   1670  elapsed = 02:12  loss = 1.1957e+00  error = 1.0614e-01  l1 = 0.991114  l2 = 0.003831\n",
            "nt_epoch =   1680  elapsed = 02:13  loss = 1.1845e+00  error = 1.0375e-01  l1 = 0.991086  l2 = 0.003815\n",
            "nt_epoch =   1690  elapsed = 02:14  loss = 1.1741e+00  error = 1.0169e-01  l1 = 0.991029  l2 = 0.003802\n",
            "nt_epoch =   1700  elapsed = 02:15  loss = 1.1617e+00  error = 9.9225e-02  l1 = 0.991076  l2 = 0.003786\n",
            "nt_epoch =   1710  elapsed = 02:15  loss = 1.1520e+00  error = 9.7315e-02  l1 = 0.991485  l2 = 0.003776\n",
            "nt_epoch =   1720  elapsed = 02:16  loss = 1.1405e+00  error = 9.6017e-02  l1 = 0.991392  l2 = 0.003767\n",
            "nt_epoch =   1730  elapsed = 02:17  loss = 1.1292e+00  error = 9.4092e-02  l1 = 0.991167  l2 = 0.003754\n",
            "nt_epoch =   1740  elapsed = 02:18  loss = 1.1158e+00  error = 9.1455e-02  l1 = 0.992072  l2 = 0.003740\n",
            "nt_epoch =   1750  elapsed = 02:18  loss = 1.1006e+00  error = 9.0042e-02  l1 = 0.991820  l2 = 0.003730\n",
            "nt_epoch =   1760  elapsed = 02:19  loss = 1.0856e+00  error = 8.5587e-02  l1 = 0.991901  l2 = 0.003702\n",
            "nt_epoch =   1770  elapsed = 02:20  loss = 1.0743e+00  error = 8.4467e-02  l1 = 0.991852  l2 = 0.003695\n",
            "nt_epoch =   1780  elapsed = 02:21  loss = 1.0657e+00  error = 8.1949e-02  l1 = 0.991659  l2 = 0.003678\n",
            "nt_epoch =   1790  elapsed = 02:21  loss = 1.0558e+00  error = 7.9400e-02  l1 = 0.992227  l2 = 0.003664\n",
            "nt_epoch =   1800  elapsed = 02:22  loss = 1.0443e+00  error = 7.9724e-02  l1 = 0.992482  l2 = 0.003667\n",
            "nt_epoch =   1810  elapsed = 02:23  loss = 1.0345e+00  error = 7.5801e-02  l1 = 0.992379  l2 = 0.003641\n",
            "nt_epoch =   1820  elapsed = 02:23  loss = 1.0232e+00  error = 7.3107e-02  l1 = 0.992430  l2 = 0.003624\n",
            "nt_epoch =   1830  elapsed = 02:24  loss = 1.0146e+00  error = 7.2886e-02  l1 = 0.992197  l2 = 0.003622\n",
            "nt_epoch =   1840  elapsed = 02:25  loss = 1.0088e+00  error = 7.2143e-02  l1 = 0.992400  l2 = 0.003618\n",
            "nt_epoch =   1850  elapsed = 02:26  loss = 9.9863e-01  error = 6.9625e-02  l1 = 0.992823  l2 = 0.003604\n",
            "nt_epoch =   1860  elapsed = 02:26  loss = 9.8768e-01  error = 6.7833e-02  l1 = 0.992507  l2 = 0.003591\n",
            "nt_epoch =   1870  elapsed = 02:27  loss = 9.7826e-01  error = 6.6230e-02  l1 = 0.992328  l2 = 0.003580\n",
            "nt_epoch =   1880  elapsed = 02:28  loss = 9.7129e-01  error = 6.3752e-02  l1 = 0.992298  l2 = 0.003564\n",
            "nt_epoch =   1890  elapsed = 02:29  loss = 9.5855e-01  error = 6.3653e-02  l1 = 0.992836  l2 = 0.003566\n",
            "nt_epoch =   1900  elapsed = 02:29  loss = 9.5004e-01  error = 6.2674e-02  l1 = 0.992631  l2 = 0.003559\n",
            "nt_epoch =   1910  elapsed = 02:30  loss = 9.4427e-01  error = 6.1643e-02  l1 = 0.992192  l2 = 0.003551\n",
            "nt_epoch =   1920  elapsed = 02:31  loss = 9.3531e-01  error = 6.0223e-02  l1 = 0.992506  l2 = 0.003543\n",
            "nt_epoch =   1930  elapsed = 02:32  loss = 9.2958e-01  error = 5.9696e-02  l1 = 0.992858  l2 = 0.003540\n",
            "nt_epoch =   1940  elapsed = 02:32  loss = 9.2324e-01  error = 5.8290e-02  l1 = 0.992627  l2 = 0.003531\n",
            "nt_epoch =   1950  elapsed = 02:33  loss = 9.1745e-01  error = 5.7378e-02  l1 = 0.992547  l2 = 0.003525\n",
            "nt_epoch =   1960  elapsed = 02:34  loss = 9.1112e-01  error = 5.6663e-02  l1 = 0.992673  l2 = 0.003521\n",
            "nt_epoch =   1970  elapsed = 02:35  loss = 9.0058e-01  error = 5.4430e-02  l1 = 0.992825  l2 = 0.003507\n",
            "nt_epoch =   1980  elapsed = 02:35  loss = 8.8735e-01  error = 5.1354e-02  l1 = 0.993074  l2 = 0.003488\n",
            "nt_epoch =   1990  elapsed = 02:36  loss = 8.7868e-01  error = 5.0037e-02  l1 = 0.992546  l2 = 0.003478\n",
            "==================\n",
            "Training finished (epoch 100): duration = 02:37  error = 4.9662e-02  l1 = 0.992574  l2 = 0.003476\n",
            "\n",
            "Training started\n",
            "================\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_9 (Lambda)            (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 81)                4131      \n",
            "=================================================================\n",
            "Total params: 9,331\n",
            "Trainable params: 9,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "—— Starting Adam optimization ——\n",
            "tf_epoch =      0  elapsed = 02:37  loss = 1.1749e+04  error = 6.1151e-01  l1 = -0.000980  l2 = 0.002476\n",
            "tf_epoch =     10  elapsed = 02:37  loss = 8.3634e+03  error = 6.1762e-01  l1 = -0.019512  l2 = 0.002496\n",
            "tf_epoch =     20  elapsed = 02:38  loss = 5.9600e+03  error = 6.2033e-01  l1 = -0.041889  l2 = 0.002550\n",
            "tf_epoch =     30  elapsed = 02:38  loss = 5.4391e+03  error = 6.2255e-01  l1 = -0.065971  l2 = 0.002613\n",
            "tf_epoch =     40  elapsed = 02:39  loss = 4.6076e+03  error = 6.2358e-01  l1 = -0.086823  l2 = 0.002673\n",
            "tf_epoch =     50  elapsed = 02:39  loss = 3.7663e+03  error = 6.2297e-01  l1 = -0.100870  l2 = 0.002721\n",
            "tf_epoch =     60  elapsed = 02:40  loss = 3.1063e+03  error = 6.2309e-01  l1 = -0.105802  l2 = 0.002736\n",
            "tf_epoch =     70  elapsed = 02:40  loss = 2.6841e+03  error = 6.2690e-01  l1 = -0.099218  l2 = 0.002691\n",
            "tf_epoch =     80  elapsed = 02:41  loss = 2.4200e+03  error = 6.2970e-01  l1 = -0.082873  l2 = 0.002621\n",
            "tf_epoch =     90  elapsed = 02:41  loss = 2.2117e+03  error = 6.3017e-01  l1 = -0.061496  l2 = 0.002550\n",
            "—— Starting LBFGS optimization ——\n",
            "nt_epoch =     10  elapsed = 02:42  loss = 1.0364e+03  error = 3.6698e-01  l1 = 0.350612  l2 = 0.002914\n",
            "nt_epoch =     20  elapsed = 02:43  loss = 6.4692e+02  error = 8.2838e-01  l1 = 0.446938  l2 = 0.006696\n",
            "nt_epoch =     30  elapsed = 02:44  loss = 4.7059e+02  error = 2.9589e+00  l1 = 0.747997  l2 = 0.021218\n",
            "nt_epoch =     40  elapsed = 02:44  loss = 3.0373e+02  error = 2.5774e+00  l1 = 0.909326  l2 = 0.019303\n",
            "nt_epoch =     50  elapsed = 02:45  loss = 2.5686e+02  error = 2.6602e+00  l1 = 0.956189  l2 = 0.019979\n",
            "nt_epoch =     60  elapsed = 02:46  loss = 1.9858e+02  error = 2.5473e+00  l1 = 0.972362  l2 = 0.019312\n",
            "nt_epoch =     70  elapsed = 02:47  loss = 1.4696e+02  error = 2.2681e+00  l1 = 0.959015  l2 = 0.017492\n",
            "nt_epoch =     80  elapsed = 02:47  loss = 1.2637e+02  error = 2.0127e+00  l1 = 0.947848  l2 = 0.015830\n",
            "nt_epoch =     90  elapsed = 02:48  loss = 1.1695e+02  error = 1.9332e+00  l1 = 0.947553  l2 = 0.015323\n",
            "nt_epoch =    100  elapsed = 02:49  loss = 1.0581e+02  error = 1.7491e+00  l1 = 0.956664  l2 = 0.014180\n",
            "nt_epoch =    110  elapsed = 02:50  loss = 9.3185e+01  error = 1.7186e+00  l1 = 0.977912  l2 = 0.014054\n",
            "nt_epoch =    120  elapsed = 02:50  loss = 8.1987e+01  error = 1.7071e+00  l1 = 0.987654  l2 = 0.014011\n",
            "nt_epoch =    130  elapsed = 02:51  loss = 7.3570e+01  error = 1.6548e+00  l1 = 0.992669  l2 = 0.013695\n",
            "nt_epoch =    140  elapsed = 02:52  loss = 6.5595e+01  error = 1.5402e+00  l1 = 0.990705  l2 = 0.012959\n",
            "nt_epoch =    150  elapsed = 02:53  loss = 5.7625e+01  error = 1.3657e+00  l1 = 0.986992  l2 = 0.011836\n",
            "nt_epoch =    160  elapsed = 02:53  loss = 5.0863e+01  error = 1.2220e+00  l1 = 0.992631  l2 = 0.010939\n",
            "nt_epoch =    170  elapsed = 02:54  loss = 4.6486e+01  error = 1.1108e+00  l1 = 0.988703  l2 = 0.010219\n",
            "nt_epoch =    180  elapsed = 02:55  loss = 4.3092e+01  error = 1.0124e+00  l1 = 0.992914  l2 = 0.009606\n",
            "nt_epoch =    190  elapsed = 02:56  loss = 4.0251e+01  error = 9.2935e-01  l1 = 0.992857  l2 = 0.009077\n",
            "nt_epoch =    200  elapsed = 02:56  loss = 3.6803e+01  error = 8.2034e-01  l1 = 0.988527  l2 = 0.008369\n",
            "nt_epoch =    210  elapsed = 02:57  loss = 3.3874e+01  error = 7.8630e-01  l1 = 0.993137  l2 = 0.008167\n",
            "nt_epoch =    220  elapsed = 02:58  loss = 3.1431e+01  error = 7.2300e-01  l1 = 0.984838  l2 = 0.007738\n",
            "nt_epoch =    230  elapsed = 02:59  loss = 2.9249e+01  error = 7.3489e-01  l1 = 0.991578  l2 = 0.007835\n",
            "nt_epoch =    240  elapsed = 02:59  loss = 2.7386e+01  error = 6.9904e-01  l1 = 0.980696  l2 = 0.007572\n",
            "nt_epoch =    250  elapsed = 03:00  loss = 2.4794e+01  error = 6.6891e-01  l1 = 0.980444  l2 = 0.007379\n",
            "nt_epoch =    260  elapsed = 03:01  loss = 2.3365e+01  error = 6.7652e-01  l1 = 0.981392  l2 = 0.007431\n",
            "nt_epoch =    270  elapsed = 03:01  loss = 2.2150e+01  error = 6.4534e-01  l1 = 0.976429  l2 = 0.007216\n",
            "nt_epoch =    280  elapsed = 03:02  loss = 2.1268e+01  error = 6.2942e-01  l1 = 0.976259  l2 = 0.007115\n",
            "nt_epoch =    290  elapsed = 03:03  loss = 2.0723e+01  error = 6.2430e-01  l1 = 0.976563  l2 = 0.007083\n",
            "nt_epoch =    300  elapsed = 03:04  loss = 2.0057e+01  error = 6.0691e-01  l1 = 0.976084  l2 = 0.006971\n",
            "nt_epoch =    310  elapsed = 03:04  loss = 1.9494e+01  error = 5.9524e-01  l1 = 0.978563  l2 = 0.006904\n",
            "nt_epoch =    320  elapsed = 03:05  loss = 1.8882e+01  error = 5.9047e-01  l1 = 0.979706  l2 = 0.006878\n",
            "nt_epoch =    330  elapsed = 03:06  loss = 1.8328e+01  error = 5.7360e-01  l1 = 0.978124  l2 = 0.006765\n",
            "nt_epoch =    340  elapsed = 03:07  loss = 1.7765e+01  error = 5.5764e-01  l1 = 0.981638  l2 = 0.006675\n",
            "nt_epoch =    350  elapsed = 03:07  loss = 1.7023e+01  error = 5.4351e-01  l1 = 0.979527  l2 = 0.006578\n",
            "nt_epoch =    360  elapsed = 03:08  loss = 1.6168e+01  error = 5.3120e-01  l1 = 0.984629  l2 = 0.006516\n",
            "nt_epoch =    370  elapsed = 03:09  loss = 1.5435e+01  error = 5.1911e-01  l1 = 0.982458  l2 = 0.006432\n",
            "nt_epoch =    380  elapsed = 03:10  loss = 1.4739e+01  error = 4.8675e-01  l1 = 0.980708  l2 = 0.006220\n",
            "nt_epoch =    390  elapsed = 03:10  loss = 1.4027e+01  error = 4.6865e-01  l1 = 0.984683  l2 = 0.006118\n",
            "nt_epoch =    400  elapsed = 03:11  loss = 1.3358e+01  error = 4.5686e-01  l1 = 0.982849  l2 = 0.006037\n",
            "nt_epoch =    410  elapsed = 03:12  loss = 1.2557e+01  error = 4.4521e-01  l1 = 0.983132  l2 = 0.005964\n",
            "nt_epoch =    420  elapsed = 03:13  loss = 1.1743e+01  error = 4.4161e-01  l1 = 0.987198  l2 = 0.005954\n",
            "nt_epoch =    430  elapsed = 03:13  loss = 1.1123e+01  error = 4.3599e-01  l1 = 0.985733  l2 = 0.005913\n",
            "nt_epoch =    440  elapsed = 03:14  loss = 1.0618e+01  error = 4.2547e-01  l1 = 0.982500  l2 = 0.005836\n",
            "nt_epoch =    450  elapsed = 03:15  loss = 1.0220e+01  error = 4.1929e-01  l1 = 0.984741  l2 = 0.005804\n",
            "nt_epoch =    460  elapsed = 03:16  loss = 9.8774e+00  error = 4.1404e-01  l1 = 0.982008  l2 = 0.005762\n",
            "nt_epoch =    470  elapsed = 03:16  loss = 9.5467e+00  error = 4.1287e-01  l1 = 0.982294  l2 = 0.005755\n",
            "nt_epoch =    480  elapsed = 03:17  loss = 9.2849e+00  error = 4.0737e-01  l1 = 0.980935  l2 = 0.005716\n",
            "nt_epoch =    490  elapsed = 03:18  loss = 8.9781e+00  error = 3.9989e-01  l1 = 0.979933  l2 = 0.005665\n",
            "nt_epoch =    500  elapsed = 03:19  loss = 8.7054e+00  error = 3.9274e-01  l1 = 0.978396  l2 = 0.005615\n",
            "nt_epoch =    510  elapsed = 03:20  loss = 8.4524e+00  error = 3.7551e-01  l1 = 0.981547  l2 = 0.005515\n",
            "nt_epoch =    520  elapsed = 03:20  loss = 8.0780e+00  error = 3.7099e-01  l1 = 0.978958  l2 = 0.005478\n",
            "nt_epoch =    530  elapsed = 03:21  loss = 7.7693e+00  error = 3.5340e-01  l1 = 0.977177  l2 = 0.005360\n",
            "nt_epoch =    540  elapsed = 03:22  loss = 7.5682e+00  error = 3.4614e-01  l1 = 0.978356  l2 = 0.005318\n",
            "nt_epoch =    550  elapsed = 03:23  loss = 7.3481e+00  error = 3.3663e-01  l1 = 0.978061  l2 = 0.005256\n",
            "nt_epoch =    560  elapsed = 03:23  loss = 7.1534e+00  error = 3.2800e-01  l1 = 0.979211  l2 = 0.005205\n",
            "nt_epoch =    570  elapsed = 03:24  loss = 6.9358e+00  error = 3.1545e-01  l1 = 0.977633  l2 = 0.005120\n",
            "nt_epoch =    580  elapsed = 03:25  loss = 6.6741e+00  error = 3.0677e-01  l1 = 0.978182  l2 = 0.005067\n",
            "nt_epoch =    590  elapsed = 03:26  loss = 6.4945e+00  error = 3.0521e-01  l1 = 0.977817  l2 = 0.005056\n",
            "nt_epoch =    600  elapsed = 03:26  loss = 6.3736e+00  error = 2.9661e-01  l1 = 0.978907  l2 = 0.005004\n",
            "nt_epoch =    610  elapsed = 03:27  loss = 6.2360e+00  error = 2.9400e-01  l1 = 0.977138  l2 = 0.004982\n",
            "nt_epoch =    620  elapsed = 03:28  loss = 6.0701e+00  error = 2.8875e-01  l1 = 0.978336  l2 = 0.004952\n",
            "nt_epoch =    630  elapsed = 03:28  loss = 5.8595e+00  error = 2.7983e-01  l1 = 0.976523  l2 = 0.004890\n",
            "nt_epoch =    640  elapsed = 03:29  loss = 5.7159e+00  error = 2.7637e-01  l1 = 0.976922  l2 = 0.004869\n",
            "nt_epoch =    650  elapsed = 03:30  loss = 5.6220e+00  error = 2.7665e-01  l1 = 0.976859  l2 = 0.004871\n",
            "nt_epoch =    660  elapsed = 03:31  loss = 5.4629e+00  error = 2.7276e-01  l1 = 0.976415  l2 = 0.004844\n",
            "nt_epoch =    670  elapsed = 03:31  loss = 5.3490e+00  error = 2.7151e-01  l1 = 0.977212  l2 = 0.004839\n",
            "nt_epoch =    680  elapsed = 03:32  loss = 5.2196e+00  error = 2.6989e-01  l1 = 0.975515  l2 = 0.004823\n",
            "nt_epoch =    690  elapsed = 03:33  loss = 5.1129e+00  error = 2.6872e-01  l1 = 0.977441  l2 = 0.004822\n",
            "nt_epoch =    700  elapsed = 03:34  loss = 5.0220e+00  error = 2.6911e-01  l1 = 0.976036  l2 = 0.004820\n",
            "nt_epoch =    710  elapsed = 03:34  loss = 4.9466e+00  error = 2.6964e-01  l1 = 0.975826  l2 = 0.004823\n",
            "nt_epoch =    720  elapsed = 03:35  loss = 4.8612e+00  error = 2.6584e-01  l1 = 0.977805  l2 = 0.004805\n",
            "nt_epoch =    730  elapsed = 03:36  loss = 4.7840e+00  error = 2.6413e-01  l1 = 0.975900  l2 = 0.004788\n",
            "nt_epoch =    740  elapsed = 03:36  loss = 4.6470e+00  error = 2.6302e-01  l1 = 0.975685  l2 = 0.004780\n",
            "nt_epoch =    750  elapsed = 03:37  loss = 4.5343e+00  error = 2.6382e-01  l1 = 0.976489  l2 = 0.004788\n",
            "nt_epoch =    760  elapsed = 03:38  loss = 4.4263e+00  error = 2.6326e-01  l1 = 0.976564  l2 = 0.004784\n",
            "nt_epoch =    770  elapsed = 03:39  loss = 4.3543e+00  error = 2.6087e-01  l1 = 0.976834  l2 = 0.004770\n",
            "nt_epoch =    780  elapsed = 03:40  loss = 4.2868e+00  error = 2.5809e-01  l1 = 0.975852  l2 = 0.004749\n",
            "nt_epoch =    790  elapsed = 03:40  loss = 4.2228e+00  error = 2.5801e-01  l1 = 0.976619  l2 = 0.004751\n",
            "nt_epoch =    800  elapsed = 03:41  loss = 4.1620e+00  error = 2.5782e-01  l1 = 0.975462  l2 = 0.004746\n",
            "nt_epoch =    810  elapsed = 03:42  loss = 4.1042e+00  error = 2.5737e-01  l1 = 0.976549  l2 = 0.004747\n",
            "nt_epoch =    820  elapsed = 03:42  loss = 4.0123e+00  error = 2.5910e-01  l1 = 0.976100  l2 = 0.004756\n",
            "nt_epoch =    830  elapsed = 03:43  loss = 3.9594e+00  error = 2.5939e-01  l1 = 0.976626  l2 = 0.004760\n",
            "nt_epoch =    840  elapsed = 03:44  loss = 3.9152e+00  error = 2.5910e-01  l1 = 0.977271  l2 = 0.004760\n",
            "nt_epoch =    850  elapsed = 03:45  loss = 3.8591e+00  error = 2.5835e-01  l1 = 0.976525  l2 = 0.004753\n",
            "nt_epoch =    860  elapsed = 03:45  loss = 3.8017e+00  error = 2.5714e-01  l1 = 0.976719  l2 = 0.004746\n",
            "nt_epoch =    870  elapsed = 03:46  loss = 3.7642e+00  error = 2.5796e-01  l1 = 0.976903  l2 = 0.004752\n",
            "nt_epoch =    880  elapsed = 03:47  loss = 3.7323e+00  error = 2.5749e-01  l1 = 0.977640  l2 = 0.004751\n",
            "nt_epoch =    890  elapsed = 03:48  loss = 3.6977e+00  error = 2.5804e-01  l1 = 0.977938  l2 = 0.004756\n",
            "nt_epoch =    900  elapsed = 03:49  loss = 3.6545e+00  error = 2.5699e-01  l1 = 0.978215  l2 = 0.004750\n",
            "nt_epoch =    910  elapsed = 03:49  loss = 3.6282e+00  error = 2.5621e-01  l1 = 0.977771  l2 = 0.004743\n",
            "nt_epoch =    920  elapsed = 03:50  loss = 3.5975e+00  error = 2.5574e-01  l1 = 0.977355  l2 = 0.004739\n",
            "nt_epoch =    930  elapsed = 03:51  loss = 3.5662e+00  error = 2.5480e-01  l1 = 0.977803  l2 = 0.004735\n",
            "nt_epoch =    940  elapsed = 03:52  loss = 3.5327e+00  error = 2.5351e-01  l1 = 0.976708  l2 = 0.004723\n",
            "nt_epoch =    950  elapsed = 03:52  loss = 3.5028e+00  error = 2.5306e-01  l1 = 0.977436  l2 = 0.004722\n",
            "nt_epoch =    960  elapsed = 03:53  loss = 3.4721e+00  error = 2.5292e-01  l1 = 0.977726  l2 = 0.004722\n",
            "nt_epoch =    970  elapsed = 03:54  loss = 3.4399e+00  error = 2.5196e-01  l1 = 0.977112  l2 = 0.004714\n",
            "nt_epoch =    980  elapsed = 03:55  loss = 3.4049e+00  error = 2.5086e-01  l1 = 0.977916  l2 = 0.004710\n",
            "nt_epoch =    990  elapsed = 03:55  loss = 3.3747e+00  error = 2.5054e-01  l1 = 0.977334  l2 = 0.004706\n",
            "nt_epoch =   1000  elapsed = 03:56  loss = 3.3492e+00  error = 2.4879e-01  l1 = 0.977754  l2 = 0.004696\n",
            "nt_epoch =   1010  elapsed = 03:57  loss = 3.3046e+00  error = 2.4674e-01  l1 = 0.977382  l2 = 0.004682\n",
            "nt_epoch =   1020  elapsed = 03:58  loss = 3.2812e+00  error = 2.4672e-01  l1 = 0.977650  l2 = 0.004683\n",
            "nt_epoch =   1030  elapsed = 03:58  loss = 3.2549e+00  error = 2.4611e-01  l1 = 0.978135  l2 = 0.004680\n",
            "nt_epoch =   1040  elapsed = 03:59  loss = 3.2282e+00  error = 2.4494e-01  l1 = 0.977784  l2 = 0.004672\n",
            "nt_epoch =   1050  elapsed = 04:00  loss = 3.2095e+00  error = 2.4400e-01  l1 = 0.977978  l2 = 0.004666\n",
            "nt_epoch =   1060  elapsed = 04:00  loss = 3.1769e+00  error = 2.4248e-01  l1 = 0.978452  l2 = 0.004658\n",
            "nt_epoch =   1070  elapsed = 04:01  loss = 3.1515e+00  error = 2.4169e-01  l1 = 0.979083  l2 = 0.004655\n",
            "nt_epoch =   1080  elapsed = 04:02  loss = 3.1299e+00  error = 2.4118e-01  l1 = 0.978938  l2 = 0.004651\n",
            "nt_epoch =   1090  elapsed = 04:03  loss = 3.1065e+00  error = 2.3962e-01  l1 = 0.978578  l2 = 0.004640\n",
            "nt_epoch =   1100  elapsed = 04:03  loss = 3.0787e+00  error = 2.3823e-01  l1 = 0.979448  l2 = 0.004634\n",
            "nt_epoch =   1110  elapsed = 04:04  loss = 3.0546e+00  error = 2.3672e-01  l1 = 0.979255  l2 = 0.004624\n",
            "nt_epoch =   1120  elapsed = 04:05  loss = 3.0331e+00  error = 2.3500e-01  l1 = 0.979654  l2 = 0.004614\n",
            "nt_epoch =   1130  elapsed = 04:06  loss = 3.0103e+00  error = 2.3308e-01  l1 = 0.979615  l2 = 0.004602\n",
            "nt_epoch =   1140  elapsed = 04:06  loss = 2.9950e+00  error = 2.3140e-01  l1 = 0.980464  l2 = 0.004594\n",
            "nt_epoch =   1150  elapsed = 04:07  loss = 2.9767e+00  error = 2.2940e-01  l1 = 0.980747  l2 = 0.004582\n",
            "nt_epoch =   1160  elapsed = 04:08  loss = 2.9604e+00  error = 2.2807e-01  l1 = 0.980486  l2 = 0.004573\n",
            "nt_epoch =   1170  elapsed = 04:09  loss = 2.9442e+00  error = 2.2629e-01  l1 = 0.980832  l2 = 0.004563\n",
            "nt_epoch =   1180  elapsed = 04:09  loss = 2.9351e+00  error = 2.2465e-01  l1 = 0.981558  l2 = 0.004555\n",
            "nt_epoch =   1190  elapsed = 04:10  loss = 2.9196e+00  error = 2.2424e-01  l1 = 0.981059  l2 = 0.004550\n",
            "nt_epoch =   1200  elapsed = 04:11  loss = 2.9061e+00  error = 2.2226e-01  l1 = 0.981245  l2 = 0.004538\n",
            "nt_epoch =   1210  elapsed = 04:12  loss = 2.8914e+00  error = 2.2076e-01  l1 = 0.982148  l2 = 0.004532\n",
            "nt_epoch =   1220  elapsed = 04:12  loss = 2.8749e+00  error = 2.1926e-01  l1 = 0.981785  l2 = 0.004521\n",
            "nt_epoch =   1230  elapsed = 04:13  loss = 2.8598e+00  error = 2.1734e-01  l1 = 0.981999  l2 = 0.004509\n",
            "nt_epoch =   1240  elapsed = 04:14  loss = 2.8417e+00  error = 2.1544e-01  l1 = 0.982277  l2 = 0.004498\n",
            "nt_epoch =   1250  elapsed = 04:15  loss = 2.8298e+00  error = 2.1476e-01  l1 = 0.981764  l2 = 0.004492\n",
            "nt_epoch =   1260  elapsed = 04:15  loss = 2.8149e+00  error = 2.1240e-01  l1 = 0.982470  l2 = 0.004479\n",
            "nt_epoch =   1270  elapsed = 04:16  loss = 2.7994e+00  error = 2.1041e-01  l1 = 0.982640  l2 = 0.004467\n",
            "nt_epoch =   1280  elapsed = 04:17  loss = 2.7892e+00  error = 2.1065e-01  l1 = 0.983183  l2 = 0.004471\n",
            "nt_epoch =   1290  elapsed = 04:18  loss = 2.7787e+00  error = 2.1051e-01  l1 = 0.983266  l2 = 0.004470\n",
            "nt_epoch =   1300  elapsed = 04:18  loss = 2.7652e+00  error = 2.0881e-01  l1 = 0.983921  l2 = 0.004461\n",
            "nt_epoch =   1310  elapsed = 04:19  loss = 2.7524e+00  error = 2.0704e-01  l1 = 0.983057  l2 = 0.004447\n",
            "nt_epoch =   1320  elapsed = 04:20  loss = 2.7376e+00  error = 2.0509e-01  l1 = 0.983214  l2 = 0.004435\n",
            "nt_epoch =   1330  elapsed = 04:20  loss = 2.7233e+00  error = 2.0260e-01  l1 = 0.984237  l2 = 0.004423\n",
            "nt_epoch =   1340  elapsed = 04:21  loss = 2.7098e+00  error = 2.0230e-01  l1 = 0.983835  l2 = 0.004420\n",
            "nt_epoch =   1350  elapsed = 04:22  loss = 2.7002e+00  error = 2.0101e-01  l1 = 0.983980  l2 = 0.004412\n",
            "nt_epoch =   1360  elapsed = 04:23  loss = 2.6884e+00  error = 1.9974e-01  l1 = 0.984220  l2 = 0.004404\n",
            "nt_epoch =   1370  elapsed = 04:23  loss = 2.6731e+00  error = 2.0031e-01  l1 = 0.983578  l2 = 0.004406\n",
            "nt_epoch =   1380  elapsed = 04:24  loss = 2.6558e+00  error = 1.9822e-01  l1 = 0.983859  l2 = 0.004394\n",
            "nt_epoch =   1390  elapsed = 04:25  loss = 2.6427e+00  error = 1.9572e-01  l1 = 0.983682  l2 = 0.004377\n",
            "nt_epoch =   1400  elapsed = 04:26  loss = 2.6285e+00  error = 1.9507e-01  l1 = 0.983598  l2 = 0.004373\n",
            "nt_epoch =   1410  elapsed = 04:26  loss = 2.6161e+00  error = 1.9436e-01  l1 = 0.984044  l2 = 0.004370\n",
            "nt_epoch =   1420  elapsed = 04:27  loss = 2.5978e+00  error = 1.9179e-01  l1 = 0.982887  l2 = 0.004350\n",
            "nt_epoch =   1430  elapsed = 04:28  loss = 2.5865e+00  error = 1.9029e-01  l1 = 0.983966  l2 = 0.004343\n",
            "nt_epoch =   1440  elapsed = 04:28  loss = 2.5763e+00  error = 1.8992e-01  l1 = 0.983939  l2 = 0.004341\n",
            "nt_epoch =   1450  elapsed = 04:29  loss = 2.5620e+00  error = 1.8871e-01  l1 = 0.983245  l2 = 0.004331\n",
            "nt_epoch =   1460  elapsed = 04:30  loss = 2.5522e+00  error = 1.8762e-01  l1 = 0.983688  l2 = 0.004326\n",
            "nt_epoch =   1470  elapsed = 04:31  loss = 2.5373e+00  error = 1.8743e-01  l1 = 0.983289  l2 = 0.004323\n",
            "nt_epoch =   1480  elapsed = 04:31  loss = 2.5217e+00  error = 1.8559e-01  l1 = 0.983291  l2 = 0.004311\n",
            "nt_epoch =   1490  elapsed = 04:32  loss = 2.5140e+00  error = 1.8540e-01  l1 = 0.982985  l2 = 0.004309\n",
            "nt_epoch =   1500  elapsed = 04:33  loss = 2.5046e+00  error = 1.8544e-01  l1 = 0.983001  l2 = 0.004310\n",
            "nt_epoch =   1510  elapsed = 04:34  loss = 2.4915e+00  error = 1.8352e-01  l1 = 0.982934  l2 = 0.004297\n",
            "nt_epoch =   1520  elapsed = 04:34  loss = 2.4832e+00  error = 1.8100e-01  l1 = 0.983131  l2 = 0.004282\n",
            "nt_epoch =   1530  elapsed = 04:35  loss = 2.4733e+00  error = 1.8022e-01  l1 = 0.983119  l2 = 0.004277\n",
            "nt_epoch =   1540  elapsed = 04:36  loss = 2.4651e+00  error = 1.7958e-01  l1 = 0.982859  l2 = 0.004272\n",
            "nt_epoch =   1550  elapsed = 04:37  loss = 2.4587e+00  error = 1.7984e-01  l1 = 0.982783  l2 = 0.004273\n",
            "nt_epoch =   1560  elapsed = 04:37  loss = 2.4462e+00  error = 1.7860e-01  l1 = 0.982985  l2 = 0.004266\n",
            "nt_epoch =   1570  elapsed = 04:38  loss = 2.4368e+00  error = 1.7797e-01  l1 = 0.982779  l2 = 0.004261\n",
            "nt_epoch =   1580  elapsed = 04:39  loss = 2.4245e+00  error = 1.7583e-01  l1 = 0.982531  l2 = 0.004247\n",
            "nt_epoch =   1590  elapsed = 04:39  loss = 2.4152e+00  error = 1.7468e-01  l1 = 0.982962  l2 = 0.004241\n",
            "nt_epoch =   1600  elapsed = 04:40  loss = 2.4059e+00  error = 1.7319e-01  l1 = 0.982607  l2 = 0.004230\n",
            "nt_epoch =   1610  elapsed = 04:41  loss = 2.3971e+00  error = 1.7097e-01  l1 = 0.982482  l2 = 0.004216\n",
            "nt_epoch =   1620  elapsed = 04:42  loss = 2.3884e+00  error = 1.6971e-01  l1 = 0.982730  l2 = 0.004209\n",
            "nt_epoch =   1630  elapsed = 04:42  loss = 2.3783e+00  error = 1.6878e-01  l1 = 0.982912  l2 = 0.004203\n",
            "nt_epoch =   1640  elapsed = 04:43  loss = 2.3690e+00  error = 1.6801e-01  l1 = 0.982717  l2 = 0.004198\n",
            "nt_epoch =   1650  elapsed = 04:44  loss = 2.3632e+00  error = 1.6646e-01  l1 = 0.982928  l2 = 0.004188\n",
            "nt_epoch =   1660  elapsed = 04:45  loss = 2.3552e+00  error = 1.6548e-01  l1 = 0.983043  l2 = 0.004183\n",
            "nt_epoch =   1670  elapsed = 04:45  loss = 2.3456e+00  error = 1.6236e-01  l1 = 0.983046  l2 = 0.004163\n",
            "nt_epoch =   1680  elapsed = 04:46  loss = 2.3354e+00  error = 1.6128e-01  l1 = 0.982940  l2 = 0.004156\n",
            "nt_epoch =   1690  elapsed = 04:47  loss = 2.3257e+00  error = 1.5900e-01  l1 = 0.983317  l2 = 0.004142\n",
            "nt_epoch =   1700  elapsed = 04:48  loss = 2.3177e+00  error = 1.5817e-01  l1 = 0.983388  l2 = 0.004137\n",
            "nt_epoch =   1710  elapsed = 04:48  loss = 2.3072e+00  error = 1.5658e-01  l1 = 0.983485  l2 = 0.004127\n",
            "nt_epoch =   1720  elapsed = 04:49  loss = 2.3012e+00  error = 1.5671e-01  l1 = 0.983339  l2 = 0.004128\n",
            "nt_epoch =   1730  elapsed = 04:50  loss = 2.2949e+00  error = 1.5551e-01  l1 = 0.983439  l2 = 0.004120\n",
            "nt_epoch =   1740  elapsed = 04:50  loss = 2.2889e+00  error = 1.5453e-01  l1 = 0.983569  l2 = 0.004115\n",
            "nt_epoch =   1750  elapsed = 04:51  loss = 2.2840e+00  error = 1.5357e-01  l1 = 0.983555  l2 = 0.004108\n",
            "nt_epoch =   1760  elapsed = 04:52  loss = 2.2811e+00  error = 1.5336e-01  l1 = 0.983450  l2 = 0.004107\n",
            "nt_epoch =   1770  elapsed = 04:53  loss = 2.2783e+00  error = 1.5073e-01  l1 = 0.983676  l2 = 0.004091\n",
            "nt_epoch =   1780  elapsed = 04:53  loss = 2.2713e+00  error = 1.5075e-01  l1 = 0.983797  l2 = 0.004091\n",
            "nt_epoch =   1790  elapsed = 04:54  loss = 2.2664e+00  error = 1.5050e-01  l1 = 0.983430  l2 = 0.004088\n",
            "nt_epoch =   1800  elapsed = 04:55  loss = 2.2617e+00  error = 1.4952e-01  l1 = 0.983568  l2 = 0.004083\n",
            "nt_epoch =   1810  elapsed = 04:56  loss = 2.2577e+00  error = 1.4866e-01  l1 = 0.984042  l2 = 0.004079\n",
            "nt_epoch =   1820  elapsed = 04:56  loss = 2.2548e+00  error = 1.4877e-01  l1 = 0.984188  l2 = 0.004080\n",
            "nt_epoch =   1830  elapsed = 04:57  loss = 2.2509e+00  error = 1.4841e-01  l1 = 0.984101  l2 = 0.004077\n",
            "nt_epoch =   1840  elapsed = 04:58  loss = 2.2478e+00  error = 1.4816e-01  l1 = 0.984218  l2 = 0.004076\n",
            "nt_epoch =   1850  elapsed = 04:58  loss = 2.2435e+00  error = 1.4768e-01  l1 = 0.984359  l2 = 0.004073\n",
            "nt_epoch =   1860  elapsed = 04:59  loss = 2.2405e+00  error = 1.4776e-01  l1 = 0.984271  l2 = 0.004074\n",
            "nt_epoch =   1870  elapsed = 05:00  loss = 2.2366e+00  error = 1.4718e-01  l1 = 0.984319  l2 = 0.004070\n",
            "nt_epoch =   1880  elapsed = 05:01  loss = 2.2327e+00  error = 1.4633e-01  l1 = 0.984412  l2 = 0.004065\n",
            "nt_epoch =   1890  elapsed = 05:01  loss = 2.2295e+00  error = 1.4572e-01  l1 = 0.984422  l2 = 0.004061\n",
            "nt_epoch =   1900  elapsed = 05:02  loss = 2.2238e+00  error = 1.4463e-01  l1 = 0.984406  l2 = 0.004054\n",
            "nt_epoch =   1910  elapsed = 05:03  loss = 2.2205e+00  error = 1.4413e-01  l1 = 0.984592  l2 = 0.004052\n",
            "nt_epoch =   1920  elapsed = 05:04  loss = 2.2157e+00  error = 1.4367e-01  l1 = 0.984829  l2 = 0.004049\n",
            "nt_epoch =   1930  elapsed = 05:04  loss = 2.2098e+00  error = 1.4243e-01  l1 = 0.985005  l2 = 0.004042\n",
            "nt_epoch =   1940  elapsed = 05:05  loss = 2.2035e+00  error = 1.4193e-01  l1 = 0.984791  l2 = 0.004038\n",
            "nt_epoch =   1950  elapsed = 05:06  loss = 2.1989e+00  error = 1.4110e-01  l1 = 0.985350  l2 = 0.004035\n",
            "nt_epoch =   1960  elapsed = 05:07  loss = 2.1939e+00  error = 1.4117e-01  l1 = 0.985342  l2 = 0.004035\n",
            "nt_epoch =   1970  elapsed = 05:07  loss = 2.1900e+00  error = 1.4061e-01  l1 = 0.985208  l2 = 0.004031\n",
            "nt_epoch =   1980  elapsed = 05:08  loss = 2.1837e+00  error = 1.3957e-01  l1 = 0.985790  l2 = 0.004026\n",
            "nt_epoch =   1990  elapsed = 05:09  loss = 2.1787e+00  error = 1.3962e-01  l1 = 0.985700  l2 = 0.004026\n",
            "==================\n",
            "Training finished (epoch 100): duration = 05:09  error = 1.3879e-01  l1 = 0.985784  l2 = 0.004021\n",
            "l1:  0.99257386\n",
            "l2:  0.003475621\n",
            "noisy l1:  0.9857842\n",
            "noisy l2:  0.004021392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUtmuGlpw1e6",
        "outputId": "564bd385-a6e1-4c64-ab76-dc6797cbf85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "plot_ide_disc_results(x_star, t_star, idx_t_0, idx_t_1, x_0, u_0, x_1, u_1,\n",
        "  ub, lb, U_1_pred, Exact_u, lambda_1_pred, lambda_1_pred_noisy, lambda_2_pred, lambda_2_pred_noisy, x_star, t_star)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 388.543x360.199 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}